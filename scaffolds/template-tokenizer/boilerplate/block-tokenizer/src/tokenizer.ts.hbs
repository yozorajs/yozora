import type { YastNode } from '@yozora/ast'
import type { NodePoint } from '@yozora/character'
import type {
  PhrasingContentLine,
  ResultOfEatAndInterruptPreviousSibling,
  ResultOfEatContinuationText,
  ResultOfEatLazyContinuationText,
  ResultOfEatOpener,
  ResultOfParse,
  Tokenizer,
  TokenizerMatchBlockHook,
  TokenizerParseBlockHook,
  TokenizerPostMatchBlockHook,
  YastBlockToken,
} from '@yozora/core-tokenizer'
import {
  BaseTokenizer,
  calcEndYastNodePoint,
  calcStartYastNodePoint,
} from '@yozora/core-tokenizer'
import type { Node, T, Token, TokenizerProps } from './types'
import { {{{pascalCase tokenizerName}}}Type, uniqueName } from './types'

/**
 * Lexical Analyzer for {{{pascalCase tokenizerName}}}
 */
export class {{{pascalCase tokenizerName}}}Tokenizer
  extends BaseTokenizer
  implements
    Tokenizer{{#if usingHooks}},{{/if}}
{{#if useTokenizerMatchBlockHook}}
    TokenizerMatchBlockHook<T, Token>{{#if TokenizerMatchBlockHook__isNotLastHook}},{{/if}}
{{/if}}
{{#if useTokenizerPostMatchBlockHook}}
    TokenizerPostMatchBlockHook{{#if TokenizerPostMatchBlockHook__isNotLastHook}},{{/if}}
{{/if}}
{{#if useTokenizerParseBlockHook}}
    TokenizerParseBlockHook<T, Token, Node>{{#if TokenizerParseBlockHook__isNotLastHook}},{{/if}}
{{/if}} {
  public readonly isContainerBlock = false

  /* istanbul ignore next */
  constructor(props: TokenizerProps = {}) {
    super({
      name: uniqueName,
      priority: props.priority,
    })
  }
{{#if useTokenizerMatchBlockHook}}

  /**
   * @override
   * @see TokenizerMatchBlockHook
   */
  public eatOpener(
    line: Readonly<PhrasingContentLine>,
    parentToken: Readonly<YastBlockToken>,
  ): ResultOfEatOpener<T, Token> {
    const { nodePoints, startIndex, endIndex, firstNonWhitespaceIndex } = line
    if (firstNonWhitespaceIndex >= endIndex) return null

    const nextIndex = endIndex
    const token: Token = {
      nodeType: {{{pascalCase tokenizerName}}}Type,
      position: {
        start: calcStartYastNodePoint(nodePoints, startIndex),
        end: calcEndYastNodePoint(nodePoints, nextIndex - 1),
      },
      lines: [{ ...line }],
    }

    return { token, nextIndex }
  }

  // /**
  //  * @override
  //  * @see TokenizerMatchBlockHook
  //  */
  // public eatAndInterruptPreviousSibling(
  //   line: Readonly<PhrasingContentLine>,
  //   prevSiblingToken: Readonly<YastBlockToken>,
  //   parentToken: Readonly<YastBlockToken>,
  // ): ResultOfEatAndInterruptPreviousSibling<T, Token> {
  //   return null
  // }

  // /**
  //  * @override
  //  * @see TokenizerMatchBlockHook
  //  */
  // public eatContinuationText(
  //   line: Readonly<PhrasingContentLine>,
  //   token: Token,
  //   parentToken: Readonly<YastBlockToken>,
  // ): ResultOfEatContinuationText {
  //   return { status: 'notMatched' }
  // }

  // /**
  //  * @override
  //  * @see TokenizerMatchBlockHook
  //  */
  // public eatLazyContinuationText(
  //   line: Readonly<PhrasingContentLine>,
  //   token: Token,
  //   parentToken: Readonly<YastBlockToken>,
  // ): ResultOfEatLazyContinuationText {
  //   const result = this.eatContinuationText(line, token, parentToken)
  //   return result as ResultOfEatLazyContinuationText
  // }
{{/if}}
{{#if useTokenizerPostMatchBlockHook}}

  /**
   * @override
   * @see TokenizerPostMatchBlockHook
   */
  public transformMatch(
    tokens: ReadonlyArray<YastBlockToken>,
    nodePoints: ReadonlyArray<NodePoint>,
  ): YastBlockToken[] {
    return tokens.slice()
  }
{{/if}}
{{#if useTokenizerParseBlockHook}}

  /**
   * @override
   * @see TokenizerParseBlockHook
   */
  public parseBlock(
    token: Readonly<Token>,
    children?: YastNode[],
  ): ResultOfParse<T, Node> {
    const node: Node = { type: token.nodeType }
    return { classification: 'flow', node }
  }
{{/if}}
}
