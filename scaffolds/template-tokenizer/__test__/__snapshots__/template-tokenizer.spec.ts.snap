// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`new-tokenizer monorepo block: __test__/answer.ts 1`] = `
"import { createTokenizerTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import WawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new WawTokenizer())

// Generate answers for custom test cases
void createTokenizerTester(parser)
  .scan('fixtures', __dirname)
  .runAnswer()
"
`;

exports[`new-tokenizer monorepo block: __test__/fixtures/basic.json 1`] = `
"{
  "title": "",
  "cases": [
    {
      "description": "case#0",
      "input": "???????",
      "parseAnswer": {
        "type": "root",
        "children": [
          {
            "type": "thematicBreak",
            "position": {
              "start": {
                "line": 1,
                "column": 1,
                "offset": 0
              },
              "end": {
                "line": 1,
                "column": 8,
                "offset": 7
              }
            }
          }
        ],
        "position": {
          "start": {
            "line": 1,
            "column": 1,
            "offset": 0
          },
          "end": {
            "line": 1,
            "column": 8,
            "offset": 7
          }
        }
      }
    }
  ]
}"
`;

exports[`new-tokenizer monorepo block: __test__/waw.spec.ts 1`] = `
"import { createTokenizerTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import WawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new WawTokenizer())

// Run official test cases
void createTokenizerTester(parser)
  .scan([
    'gfm/**/*.json',
    // The following cases are conflict when enabled GFM autolink (extension)
    // @see https://github.github.com/gfm/#example-616
    '!gfm/**/#616.json',
    '!gfm/**/#619.json',
    '!gfm/**/#620.json',
  ])
  .scan('custom')
  .runTest()

// Run custom test cases
void createTokenizerTester(parser)
  .scan('fixtures', __dirname)
  .runTest()
"
`;

exports[`new-tokenizer monorepo block: README.md 1`] = `
"<header>
  <h1 align="center">
    <a href="https://github.com/guanghechen/yozora/tree/main/tokenizers/waw#readme">@yozora/tokenizer-waw</a>
  </h1>
  <div align="center">
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-waw">
      <img
        alt="Npm Version"
        src="https://img.shields.io/npm/v/@yozora/tokenizer-waw.svg"
      />
    </a>
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-waw">
      <img
        alt="Npm Download"
        src="https://img.shields.io/npm/dm/@yozora/tokenizer-waw.svg"
      />
    </a>
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-waw">
      <img
        alt="Npm License"
        src="https://img.shields.io/npm/l/@yozora/tokenizer-waw.svg"
      />
    </a>
    <a href="#install">
      <img
        alt="Module Formats: cjs, esm"
        src="https://img.shields.io/badge/module_formats-cjs%2C%20esm-green.svg"
      />
    </a>
    <a href="https://github.com/nodejs/node">
      <img
        alt="Node.js Version"
        src="https://img.shields.io/node/v/@yozora/tokenizer-waw"
      />
    </a>
    <a href="https://github.com/yozorajs/yozora/blob/main/packages/core-tokenizer#readme">
      <img
        alt="Yozora Version"
        src="https://img.shields.io/npm/dependency-version/@yozora/tokenizer-waw/@yozora/core-tokenizer"
      />
    </a>
    <a href="https://github.com/prettier/prettier">
      <img
        alt="Code Style: prettier"
        src="https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square"
      />
    </a>
  </div>
</header>
<br/>


See [@yozora/tokenizer-waw documentation](https://yozora.guanghechen.com/docs/package/@yozora/tokenizer-waw) for details.

Some descriptions.

## Install

* npm

  \`\`\`bash
  npm install --save @yozora/tokenizer-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

* yarn

  \`\`\`bash
  yarn add @yozora/tokenizer-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

## Usage


## Related


[homepage]: https://github.com/guanghechen/yozora/tree/main/tokenizers/waw#readme
"
`;

exports[`new-tokenizer monorepo block: console 1`] = `
[
  [
    "answers:",
    {
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "paragraph",
      "isBlockTokenizer": true,
      "isMonorepo": true,
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "Some descriptions",
      "packageLocation": "tokenizers/waw",
      "packageName": "@yozora/tokenizer-waw",
      "packageUsage": "Some descriptions.",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/yozora/tree/main/tokenizers/waw#readme",
      "repositoryName": "yozora",
      "tokenizerCategory": "block",
      "tokenizerName": "waw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "../../tsconfig",
      "tsconfigSrcExtends": "../../tsconfig.settings",
    },
  ],
]
`;

exports[`new-tokenizer monorepo block: package.json 1`] = `
"{
  "name": "@yozora/tokenizer-waw",
  "version": "<LATEST>",
  "author": {
    "name": "guanghechen",
    "url": "https://github.com/guanghechen/"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/guanghechen/yozora.git",
    "directory": "tokenizers/waw"
  },
  "homepage": "https://github.com/guanghechen/yozora/tree/main/tokenizers/waw#readme",
  "keywords": [],
  "type": "module",
  "exports": {
    "import": "./lib/esm/index.mjs",
    "require": "./lib/cjs/index.cjs"
  },
  "types": "lib/types/index.d.ts",
  "source": "src/index.ts",
  "license": "MIT",
  "engines": {
    "node": ">= 16.0.0"
  },
  "files": [
    "lib/",
    "src/",
    "package.json",
    "CHANGELOG.md",
    "LICENSE",
    "README.md"
  ],
  "scripts": {
    "build": "cross-env NODE_ENV=production rollup -c ../../rollup.config.mjs",
    "prebuild": "rimraf lib/ && tsc -p tsconfig.src.json --emitDeclarationOnly",
    "prepublishOnly": "cross-env ROLLUP_SHOULD_SOURCEMAP=false yarn build",
    "test": "cross-env TS_NODE_FILES=true jest --config ../../jest.config.js --rootDir .",
    "test:update": "node -r ts-node/register -r tsconfig-paths/register __test__/answer.ts"
  },
  "dependencies": {
    "@yozora/ast": "^<LATEST>",
    "@yozora/character": "^<LATEST>",
    "@yozora/core-tokenizer": "^<LATEST>"
  },
  "devDependencies": {
    "@yozora/eslint-config": "^<LATEST>",
    "@yozora/jest-for-tokenizer": "^<LATEST>",
    "@yozora/parser": "^<LATEST>",
    "tsconfig-paths": "3.12.0",
    "typescript": "4.5.3"
  }
}
"
`;

exports[`new-tokenizer monorepo block: src/index.ts 1`] = `
"export { match as wawMatch } from './match'
export { parse as wawParse } from './parse'
export { WawTokenizer, WawTokenizer as default } from './tokenizer'
export { uniqueName as WawTokenizerName } from './types'
export type {
  IThis as IWawHookContext,
  IToken as IWawToken,
  ITokenizerProps as IWawTokenizerProps,
} from './types'
"
`;

exports[`new-tokenizer monorepo block: src/match.ts 1`] = `
"import { AsciiCodePoint, isLineEnding } from '@yozora/character'
import type {
  IMatchBlockHookCreator,
  IPhrasingContentLine,
  // IResultOfEatAndInterruptPreviousSibling,
  // IResultOfEatContinuationText,
  // IResultOfEatLazyContinuationText,
  IResultOfEatOpener,
  IYastBlockToken,
} from '@yozora/core-tokenizer'
import { calcEndYastNodePoint, calcStartYastNodePoint } from '@yozora/core-tokenizer'
import type { IThis, IToken, T } from './types'
import { WawType } from './types'

export const match: IMatchBlockHookCreator<T, IToken, IThis> = function (api) {
  return {
    isContainingBlock: false,
    eatOpener,
    // eatAndInterruptPreviousSibling,
    // eatContinuationText,
    // eatLazyContinuationText,
  }

  function eatOpener(
    line: Readonly<IPhrasingContentLine>,
    parentToken: Readonly<IYastBlockToken>,
  ): IResultOfEatOpener<T, IToken> {
    const { nodePoints, startIndex, endIndex, firstNonWhitespaceIndex } = line
    if (firstNonWhitespaceIndex + 3 >= endIndex) return null

    let i = firstNonWhitespaceIndex
    const marker = nodePoints[i].codePoint
    let c = marker
    if (
      marker !== AsciiCodePoint.QUESTION_MARK &&
      marker !== AsciiCodePoint.EXCLAMATION_MARK
    ) return null

    for (; i < endIndex; ++i) {
      c = nodePoints[i].codePoint
      if (c !== marker) break
    }
    if (i < endIndex && !isLineEnding(c)) return null

    const nextIndex = endIndex
    const token: IToken = {
      nodeType: WawType,
      position: {
        start: calcStartYastNodePoint(nodePoints, startIndex),
        end: calcEndYastNodePoint(nodePoints, nextIndex - 1),
      },
      marker,
      continuous: true,
      children: [],
    }

    return { token, nextIndex, saturated: true }
  }

  // function eatAndInterruptPreviousSibling(
  //   line: Readonly<IPhrasingContentLine>,
  //   prevSiblingToken: Readonly<IYastBlockToken>,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatAndInterruptPreviousSibling<T, IToken> {
  //   const result = this.eatOpener(line, parentToken)
  //   if (result == null) return null
  //   return {
  //     token: result.token,
  //     nextIndex: result.nextIndex,
  //     remainingSibling: prevSiblingToken,
  //   }
  // }

  // function eatContinuationText(
  //   line: Readonly<IPhrasingContentLine>,
  //   token: IToken,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatContinuationText {
  //   return { status: 'notMatched' }
  // }

  // function eatLazyContinuationText(
  //   line: Readonly<IPhrasingContentLine>,
  //   token: IToken,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatLazyContinuationText {
  //   const result = this.eatContinuationText(line, token, parentToken)
  //   return result as IResultOfEatLazyContinuationText
  // }
}
"
`;

exports[`new-tokenizer monorepo block: src/parse.ts 1`] = `
"import type { Node } from '@yozora/ast'
import type { IParseBlockHookCreator } from '@yozora/core-tokenizer'
import type { INode, IThis, IToken, T } from './types'
import { WawType } from './types'

export const parse: IParseBlockHookCreator<T, IToken, INode, IThis> = function (api) {
  return {
    parse: tokens =>
      tokens.map(token => {
        const children: Node[] = api.parseBlockTokens(token.children)
        const node: INode = {
          type: WawType,
          position: token.position,
          children,
        }
        return node
      }),
  }
}
"
`;

exports[`new-tokenizer monorepo block: src/tokenizer.ts 1`] = `
"import type {
  IBlockTokenizer,
  IMatchBlockHookCreator,
  IParseBlockHookCreator,
} from '@yozora/core-tokenizer'
import { BaseBlockTokenizer, TokenizerPriority } from '@yozora/core-tokenizer'
import { match } from './match'
import { parse } from './parse'
import type { INode, IThis, IToken, ITokenizerProps, T } from './types'
import { uniqueName } from './types'

/**
 * Lexical Analyzer for Waw
 */
export class WawTokenizer
  extends BaseBlockTokenizer<T, IToken, INode, IThis>
  implements IBlockTokenizer<T, IToken, INode, IThis>
{
  /* istanbul ignore next */
  constructor(props: ITokenizerProps = {}) {
    super({
      name: props.name ?? uniqueName,
      priority: props.priority ?? TokenizerPriority.ATOMIC,
    })
  }

  public override readonly match: IMatchBlockHookCreator<T, IToken, IThis> = match

  public override readonly parse: IParseBlockHookCreator<T, IToken, INode, IThis> = parse
}
"
`;

exports[`new-tokenizer monorepo block: src/types.ts 1`] = `
"import type { Parent } from '@yozora/ast'
import type {
  IBaseBlockTokenizerProps,
  IPartialYastBlockToken,
  ITokenizer,
  IYastBlockToken,
} from '@yozora/core-tokenizer'

export const WawType = 'waw'
export type T = typeof WawType

export const uniqueName = '@yozora/tokenizer-waw'

export type INode = Parent<T>

export interface IToken extends IPartialYastBlockToken<T> {
  /**
   * CodePoint of '?' / '!'
   */
  marker: number
  /**
   * Whether there are no internal spaces between marker characters
   */
  continuous: boolean
  /**
   *
   */
  children: IYastBlockToken[]
}

export type IThis = ITokenizer

export type ITokenizerProps = Partial<IBaseBlockTokenizerProps>
"
`;

exports[`new-tokenizer monorepo block: tsconfig.json 1`] = `
"{
  "extends": "../../tsconfig",
  "compilerOptions": {
    "baseUrl": "."
  },
  "include": ["src", "script", "__test__"]
}
"
`;

exports[`new-tokenizer monorepo block: tsconfig.src.json 1`] = `
"{
  "extends": "../../tsconfig.settings",
  "compilerOptions": {
    "rootDir": "src"
  },
  "include": ["src"]
}
"
`;

exports[`new-tokenizer monorepo default: console 1`] = `
[
  [
    "answers:",
    {
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "text",
      "isInlineTokenizer": true,
      "isMonorepo": true,
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "",
      "packageLocation": "packages/tokenizer-inline-waw",
      "packageName": "@yozora/tokenizer-inline-waw",
      "packageUsage": "",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/yozora/tree/main/packages/tokenizer-inline-waw#readme",
      "repositoryName": "yozora",
      "tokenizerCategory": "inline",
      "tokenizerName": "inline-waw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "../../tsconfig",
      "tsconfigSrcExtends": "../../tsconfig.settings",
    },
  ],
]
`;

exports[`new-tokenizer monorepo inline: __test__/answer.ts 1`] = `
"import { createTokenizerTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import InlineWawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new InlineWawTokenizer())

// Generate answers for custom test cases
void createTokenizerTester(parser)
  .scan('fixtures', __dirname)
  .runAnswer()
"
`;

exports[`new-tokenizer monorepo inline: __test__/fixtures/basic.json 1`] = `
"{
  "title": "",
  "cases": [
    {
      "description": "case#0",
      "input": "???????",
      "parseAnswer": {
        "type": "root",
        "children": [
          {
            "type": "paragraph",
            "children": [
              {
                "type": "inlineWaw",
                "value": "???????",
                "position": {
                  "start": {
                    "line": 1,
                    "column": 1,
                    "offset": 0
                  },
                  "end": {
                    "line": 1,
                    "column": 8,
                    "offset": 7
                  }
                }
              }
            ],
            "position": {
              "start": {
                "line": 1,
                "column": 1,
                "offset": 0
              },
              "end": {
                "line": 1,
                "column": 8,
                "offset": 7
              }
            }
          }
        ],
        "position": {
          "start": {
            "line": 1,
            "column": 1,
            "offset": 0
          },
          "end": {
            "line": 1,
            "column": 8,
            "offset": 7
          }
        }
      }
    }
  ]
}"
`;

exports[`new-tokenizer monorepo inline: __test__/inline-waw.spec.ts 1`] = `
"import { createTokenizerTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import InlineWawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new InlineWawTokenizer())

// Run official test cases
void createTokenizerTester(parser)
  .scan([
    'gfm/**/*.json',
    // The following cases are conflict when enabled GFM autolink (extension)
    // @see https://github.github.com/gfm/#example-616
    '!gfm/**/#616.json',
    '!gfm/**/#619.json',
    '!gfm/**/#620.json',
  ])
  .scan('custom')
  .runTest()

// Run custom test cases
void createTokenizerTester(parser)
  .scan('fixtures', __dirname)
  .runTest()
"
`;

exports[`new-tokenizer monorepo inline: README.md 1`] = `
"<header>
  <h1 align="center">
    <a href="https://github.com/guanghechen/yozora/tree/main/tokenizers/inline-waw#readme">@yozora/tokenizer-inline-waw</a>
  </h1>
  <div align="center">
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-inline-waw">
      <img
        alt="Npm Version"
        src="https://img.shields.io/npm/v/@yozora/tokenizer-inline-waw.svg"
      />
    </a>
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-inline-waw">
      <img
        alt="Npm Download"
        src="https://img.shields.io/npm/dm/@yozora/tokenizer-inline-waw.svg"
      />
    </a>
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-inline-waw">
      <img
        alt="Npm License"
        src="https://img.shields.io/npm/l/@yozora/tokenizer-inline-waw.svg"
      />
    </a>
    <a href="#install">
      <img
        alt="Module Formats: cjs, esm"
        src="https://img.shields.io/badge/module_formats-cjs%2C%20esm-green.svg"
      />
    </a>
    <a href="https://github.com/nodejs/node">
      <img
        alt="Node.js Version"
        src="https://img.shields.io/node/v/@yozora/tokenizer-inline-waw"
      />
    </a>
    <a href="https://github.com/yozorajs/yozora/blob/main/packages/core-tokenizer#readme">
      <img
        alt="Yozora Version"
        src="https://img.shields.io/npm/dependency-version/@yozora/tokenizer-inline-waw/@yozora/core-tokenizer"
      />
    </a>
    <a href="https://github.com/prettier/prettier">
      <img
        alt="Code Style: prettier"
        src="https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square"
      />
    </a>
  </div>
</header>
<br/>


See [@yozora/tokenizer-inline-waw documentation](https://yozora.guanghechen.com/docs/package/@yozora/tokenizer-inline-waw) for details.

Some descriptions.

## Install

* npm

  \`\`\`bash
  npm install --save @yozora/tokenizer-inline-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

* yarn

  \`\`\`bash
  yarn add @yozora/tokenizer-inline-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

## Usage


## Related


[homepage]: https://github.com/guanghechen/yozora/tree/main/tokenizers/inline-waw#readme
"
`;

exports[`new-tokenizer monorepo inline: console 1`] = `
[
  [
    "answers:",
    {
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "text",
      "isInlineTokenizer": true,
      "isMonorepo": true,
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "Some descriptions",
      "packageLocation": "tokenizers/inline-waw",
      "packageName": "@yozora/tokenizer-inline-waw",
      "packageUsage": "Some descriptions.",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/yozora/tree/main/tokenizers/inline-waw#readme",
      "repositoryName": "yozora",
      "tokenizerCategory": "inline",
      "tokenizerName": "inlineWaw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "../../tsconfig",
      "tsconfigSrcExtends": "../../tsconfig.settings",
    },
  ],
]
`;

exports[`new-tokenizer monorepo inline: package.json 1`] = `
"{
  "name": "@yozora/tokenizer-inline-waw",
  "version": "<LATEST>",
  "author": {
    "name": "guanghechen",
    "url": "https://github.com/guanghechen/"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/guanghechen/yozora.git",
    "directory": "tokenizers/inline-waw"
  },
  "homepage": "https://github.com/guanghechen/yozora/tree/main/tokenizers/inline-waw#readme",
  "keywords": [],
  "type": "module",
  "exports": {
    "import": "./lib/esm/index.mjs",
    "require": "./lib/cjs/index.cjs"
  },
  "types": "lib/types/index.d.ts",
  "source": "src/index.ts",
  "license": "MIT",
  "engines": {
    "node": ">= 16.0.0"
  },
  "files": [
    "lib/",
    "src/",
    "package.json",
    "CHANGELOG.md",
    "LICENSE",
    "README.md"
  ],
  "scripts": {
    "build": "cross-env NODE_ENV=production rollup -c ../../rollup.config.mjs",
    "prebuild": "rimraf lib/ && tsc -p tsconfig.src.json --emitDeclarationOnly",
    "prepublishOnly": "cross-env ROLLUP_SHOULD_SOURCEMAP=false yarn build",
    "test": "cross-env TS_NODE_FILES=true jest --config ../../jest.config.js --rootDir .",
    "test:update": "node -r ts-node/register -r tsconfig-paths/register __test__/answer.ts"
  },
  "dependencies": {
    "@yozora/ast": "^<LATEST>",
    "@yozora/character": "^<LATEST>",
    "@yozora/core-tokenizer": "^<LATEST>"
  },
  "devDependencies": {
    "@yozora/eslint-config": "^<LATEST>",
    "@yozora/jest-for-tokenizer": "^<LATEST>",
    "@yozora/parser": "^<LATEST>",
    "tsconfig-paths": "3.12.0",
    "typescript": "4.5.3"
  }
}
"
`;

exports[`new-tokenizer monorepo inline: src/index.ts 1`] = `
"export { match as inlineWawMatch } from './match'
export { parse as inlineWawParse } from './parse'
export { InlineWawTokenizer, InlineWawTokenizer as default } from './tokenizer'
export { InlineWawType, uniqueName as InlineWawTokenizerName } from './types'
export type {
  INode as IInlineWaw,
  IThis as IInlineWawHookContext,
  IToken as IInlineWawToken,
  ITokenizerProps as IInlineWawTokenizerProps,
} from './types'
"
`;

exports[`new-tokenizer monorepo inline: src/match.ts 1`] = `
"import type { INodePoint } from '@yozora/character'
import { AsciiCodePoint } from '@yozora/character'
import type {
  IMatchInlineHookCreator,
  IResultOfProcessSingleDelimiter,
} from '@yozora/core-tokenizer'
import { eatOptionalWhitespaces, genFindDelimiter } from '@yozora/core-tokenizer'
import type { IDelimiter, IThis, IToken, T } from './types'
import { InlineWawType } from './types'

export const match: IMatchInlineHookCreator<T, IDelimiter, IToken, IThis> = function (api) {
  return {
    findDelimiter: () => genFindDelimiter<IDelimiter>(_findDelimiter),
    processSingleDelimiter,
  }

  function _findDelimiter(startIndex: number, endIndex: number): IDelimiter | null {
    const nodePoints: ReadonlyArray<INodePoint> = api.getNodePoints()
    let i = eatOptionalWhitespaces(nodePoints, startIndex, endIndex)
    if (i + 3 >= endIndex) return null

    const marker = nodePoints[i].codePoint
    let c = marker
    if (
      marker !== AsciiCodePoint.QUESTION_MARK &&
      marker !== AsciiCodePoint.EXCLAMATION_MARK
    ) return null

    for (; i < endIndex; ++i) {
      c = nodePoints[i].codePoint
      if (c !== marker) break
    }
    if (i < endIndex) return null

    const delimiter: IDelimiter = {
      type: 'full',
      startIndex,
      endIndex,
    }
    return delimiter
  }

  function processSingleDelimiter(
    delimiter: IDelimiter
  ): IResultOfProcessSingleDelimiter<T, IToken> {
    if (delimiter.type !== 'full') return []
    const token: IToken = {
      nodeType: InlineWawType,
      startIndex: delimiter.startIndex,
      endIndex: delimiter.endIndex,
    }
    return [token]
  }
}
"
`;

exports[`new-tokenizer monorepo inline: src/parse.ts 1`] = `
"import type { Node } from '@yozora/ast'
import type { INodePoint } from '@yozora/character'
import { calcEscapedStringFromNodePoints } from '@yozora/character'
import type { IParseInlineHookCreator } from '@yozora/core-tokenizer'
import type { INode, IThis, IToken, T } from './types'
import { InlineWawType } from './types'

export const parse: IParseInlineHookCreator<T, IToken, INode, IThis> = function (api) {
  return {
    parse: tokens =>
      tokens.map(token => {
        const nodePoints: ReadonlyArray<INodePoint> = api.getNodePoints()
        const { startIndex, endIndex } = token
        let value: string = calcEscapedStringFromNodePoints(
          nodePoints,
          startIndex,
          endIndex
        )

        // Remove the spaces at the end of the line and beginning of the next line.
        value = value.replace(/[^\\S\\n]*\\n[^\\S\\n]*/g, '\\n')
        const children: Node[] = api.parseInlineTokens(token.children)
        const node: INode = {
          type: InlineWawType,
          position: api.calcPosition(token),
          value,
        }
        return node
      }),
  }
}
"
`;

exports[`new-tokenizer monorepo inline: src/tokenizer.ts 1`] = `
"import type {
  IInlineTokenizer,
  IMatchInlineHookCreator,
  IParseInlineHookCreator,
} from '@yozora/core-tokenizer'
import { BaseInlineTokenizer, TokenizerPriority } from '@yozora/core-tokenizer'
import { match } from './match'
import { parse } from './parse'
import type { IDelimiter, INode, IThis, IToken, ITokenizerProps, T } from './types'
import { uniqueName } from './types'

/**
 * Lexical Analyzer for InlineWaw
 */
export class InlineWawTokenizer
  extends BaseInlineTokenizer<T, IDelimiter, IToken, INode, IThis>
  implements IInlineTokenizer<T, IDelimiter, IToken, INode, IThis> {

  /* istanbul ignore next */
  constructor(props: ITokenizerProps = {}) {
    super({
      name: props.name ?? uniqueName,
      priority: props.priority ?? TokenizerPriority.ATOMIC,
    })
  }

  public override readonly match: IMatchInlineHookCreator<T, IDelimiter, IToken, IThis> = match

  public override readonly parse: IParseInlineHookCreator<T, IToken, INode, IThis> = parse
}
"
`;

exports[`new-tokenizer monorepo inline: src/types.ts 1`] = `
"import type { Literal } from '@yozora/ast'
import type {
  IBaseInlineTokenizerProps,
  IPartialYastInlineToken,
  ITokenizer,
  IYastTokenDelimiter,
} from '@yozora/core-tokenizer'

export const InlineWawType = 'inlineWaw'
export type T = typeof InlineWawType

export const uniqueName = '@yozora/tokenizer-inline-waw'

/**
 *
 * @example
 *    \`\`\`\`markdown
 *    \`\`\`\`
 *    ===>
 *    \`\`\`js
 *    \`\`\`
 */
export type INode = Literal<T>

export type IToken = IPartialYastInlineToken<T>

export type IDelimiter = IYastTokenDelimiter

export type IThis = ITokenizer

export type ITokenizerProps = Partial<IBaseInlineTokenizerProps>
"
`;

exports[`new-tokenizer monorepo inline: tsconfig.json 1`] = `
"{
  "extends": "../../tsconfig",
  "compilerOptions": {
    "baseUrl": "."
  },
  "include": ["src", "script", "__test__"]
}
"
`;

exports[`new-tokenizer monorepo inline: tsconfig.src.json 1`] = `
"{
  "extends": "../../tsconfig.settings",
  "compilerOptions": {
    "rootDir": "src"
  },
  "include": ["src"]
}
"
`;

exports[`new-tokenizer not a monorepo block: .editorconfig 1`] = `
"root = true

[*]
charset = utf-8
indent_style = space
indent_size = 2
end_of_line = lf
insert_final_newline = true
tab_width = 2
trim_trailing_whitespace = true


[*.{md,mdx,hbs}]
insert_final_newline = false
trim_trailing_whitespace = false

[**/fixtures/**/*.json]
insert_final_newline = false
"
`;

exports[`new-tokenizer not a monorepo block: .eslintrc 1`] = `
"{
  "root": true,
  "extends": ["@yozora"],
  "rules": {},
  "overrides": []
}
"
`;

exports[`new-tokenizer not a monorepo block: .gitignore 1`] = `
".DS_Store

__tmp__/
lib/
build/
coverage/
dist/
node_modules/
release/
target/
**/*.styl.d.ts

*.tsbuildinfo
tmp/

# local env files
.env.local
.env.*.local

# Log files
npm-debug.log*
yarn-debug.log*
lerna-debug.log*
npm-error.log*
yarn-error.log*

# Editor directories and files
.idea/
.vscode/*
!.vscode/settings.json
!.vscode/launch.json

*.suo
*.ntvs*
*.njsproj
*.sln
*.sw*
"
`;

exports[`new-tokenizer not a monorepo block: .prettierrc 1`] = `
"arrowParens: avoid
bracketSpacing: true
embeddedLanguageFormatting: off
endOfLine: lf
htmlWhitespaceSensitivity: strict
jsxBracketSameLine: false
jsxSingleQuote: false
printWidth: 80
proseWrap: always
quoteProps: as-needed
semi: false
singleQuote: true
trailingComma: all
useTabs: false
"
`;

exports[`new-tokenizer not a monorepo block: __test__/answer.ts 1`] = `
"import { createTokenizerTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import WawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new WawTokenizer())

// Generate answers for custom test cases
void createTokenizerTester(parser)
  .scan('fixtures', __dirname)
  .runAnswer()
"
`;

exports[`new-tokenizer not a monorepo block: __test__/fixtures/basic.json 1`] = `
"{
  "title": "",
  "cases": [
    {
      "description": "case#0",
      "input": "???????",
      "parseAnswer": {
        "type": "root",
        "children": [
          {
            "type": "thematicBreak",
            "position": {
              "start": {
                "line": 1,
                "column": 1,
                "offset": 0
              },
              "end": {
                "line": 1,
                "column": 8,
                "offset": 7
              }
            }
          }
        ],
        "position": {
          "start": {
            "line": 1,
            "column": 1,
            "offset": 0
          },
          "end": {
            "line": 1,
            "column": 8,
            "offset": 7
          }
        }
      }
    }
  ]
}"
`;

exports[`new-tokenizer not a monorepo block: __test__/waw.spec.ts 1`] = `
"import { createTokenizerTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import WawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new WawTokenizer())

// Run official test cases
void createTokenizerTester(parser)
  .scan([
    'gfm/**/*.json',
    // The following cases are conflict when enabled GFM autolink (extension)
    // @see https://github.github.com/gfm/#example-616
    '!gfm/**/#616.json',
    '!gfm/**/#619.json',
    '!gfm/**/#620.json',
  ])
  .scan('custom')
  .runTest()

// Run custom test cases
void createTokenizerTester(parser)
  .scan('fixtures', __dirname)
  .runTest()
"
`;

exports[`new-tokenizer not a monorepo block: README.md 1`] = `
"<header>
  <h1 align="center">
    <a href="https://github.com/guanghechen/tokenizer-waw#readme">@yozora/tokenizer-waw</a>
  </h1>
  <div align="center">
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-waw">
      <img
        alt="Npm Version"
        src="https://img.shields.io/npm/v/@yozora/tokenizer-waw.svg"
      />
    </a>
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-waw">
      <img
        alt="Npm Download"
        src="https://img.shields.io/npm/dm/@yozora/tokenizer-waw.svg"
      />
    </a>
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-waw">
      <img
        alt="Npm License"
        src="https://img.shields.io/npm/l/@yozora/tokenizer-waw.svg"
      />
    </a>
    <a href="#install">
      <img
        alt="Module Formats: cjs, esm"
        src="https://img.shields.io/badge/module_formats-cjs%2C%20esm-green.svg"
      />
    </a>
    <a href="https://github.com/nodejs/node">
      <img
        alt="Node.js Version"
        src="https://img.shields.io/node/v/@yozora/tokenizer-waw"
      />
    </a>
    <a href="https://github.com/yozorajs/yozora/blob/main/packages/core-tokenizer#readme">
      <img
        alt="Yozora Version"
        src="https://img.shields.io/npm/dependency-version/@yozora/tokenizer-waw/@yozora/core-tokenizer"
      />
    </a>
    <a href="https://github.com/prettier/prettier">
      <img
        alt="Code Style: prettier"
        src="https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square"
      />
    </a>
  </div>
</header>
<br/>


See [@yozora/tokenizer-waw documentation](https://yozora.guanghechen.com/docs/package/@yozora/tokenizer-waw) for details.

Some descriptions.

## Install

* npm

  \`\`\`bash
  npm install --save @yozora/tokenizer-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

* yarn

  \`\`\`bash
  yarn add @yozora/tokenizer-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

## Usage


## Related


[homepage]: https://github.com/guanghechen/tokenizer-waw#readme
"
`;

exports[`new-tokenizer not a monorepo block: console 1`] = `
[
  [
    "answers:",
    {
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "paragraph",
      "isBlockTokenizer": true,
      "isMonorepo": false,
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "Some descriptions",
      "packageLocation": "tokenizers/waw",
      "packageName": "@yozora/tokenizer-waw",
      "packageUsage": "Some descriptions.",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/tokenizer-waw#readme",
      "repositoryName": "tokenizer-waw",
      "tokenizerCategory": "block",
      "tokenizerName": "waw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "./tsconfig.settings",
      "tsconfigSrcExtends": "./tsconfig.settings",
    },
  ],
]
`;

exports[`new-tokenizer not a monorepo block: jest.config.js 1`] = `
"const fs = require('fs')

module.exports = {
  bail: true,
  verbose: true,
  errorOnDeprecated: true,
  roots: ['src', '__test__']
    .filter(p => fs.existsSync(p))
    .map(p => \`<rootDir>/\${p}\`),
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  globals: {
    'ts-jest': {
      tsconfig: '<rootDir>/tsconfig.json',
    },
  },
  transform: {
    '^.+\\\\.tsx?$': 'ts-jest',
  },
  testURL: 'http://localhost/',
  testEnvironment: 'node',
  testRegex: '/(__test__)/[^/]+\\\\.spec\\\\.[jt]sx?$',
  testPathIgnorePatterns: ['/coverage/', '/lib/', '/node_modules/'],
  collectCoverage: false,
  coverageDirectory: '<rootDir>/coverage/',
  collectCoverageFrom: [
    '<rootDir>/src/*.{js,jsx,ts,tsx}',
    '<rootDir>/src/**/*.{js,jsx,ts,tsx}',
  ],
  coveragePathIgnorePatterns: [],
  coverageThreshold: {
    global: {
      branches: 50,
      functions: 80,
      lines: 80,
      statements: 60,
    },
  },
  coverageReporters: ['lcov', 'text', 'text-summary'],
}
"
`;

exports[`new-tokenizer not a monorepo block: package.json 1`] = `
"{
  "name": "@yozora/tokenizer-waw",
  "version": "<LATEST>",
  "author": {
    "name": "guanghechen",
    "url": "https://github.com/guanghechen/"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/guanghechen/tokenizer-waw.git"
  },
  "homepage": "https://github.com/guanghechen/tokenizer-waw#readme",
  "keywords": [],
  "type": "module",
  "exports": {
    "import": "./lib/esm/index.mjs",
    "require": "./lib/cjs/index.cjs"
  },
  "types": "lib/types/index.d.ts",
  "source": "src/index.ts",
  "license": "MIT",
  "engines": {
    "node": ">= 16.0.0"
  },
  "files": [
    "lib/",
    "src/",
    "package.json",
    "CHANGELOG.md",
    "LICENSE",
    "README.md"
  ],
  "scripts": {
    "build": "cross-env NODE_ENV=production rollup -c rollup.config.js",
    "format": "run-s format:lint:fix format:prettier",
    "format:prettier": "prettier --write .",
    "format:lint:fix": "eslint . --fix",
    "prebuild": "rimraf lib/ && tsc -p tsconfig.src.json --emitDeclarationOnly",
    "prepublishOnly": "cross-env ROLLUP_SHOULD_SOURCEMAP=false yarn build",
    "test": "cross-env TS_NODE_FILES=true jest --config jest.config.js --rootDir .",
    "test:update": "node -r ts-node/register -r tsconfig-paths/register __test__/answer.ts"
  },
  "dependencies": {
    "@yozora/ast": "^<LATEST>",
    "@yozora/character": "^<LATEST>",
    "@yozora/core-tokenizer": "^<LATEST>"
  },
  "devDependencies": {
    "@guanghechen/rollup-config": "^2.1.0",
    "@types/jest": "27.0.3",
    "@yozora/eslint-config": "^<LATEST>",
    "@yozora/jest-for-tokenizer": "^<LATEST>",
    "@yozora/parser": "^<LATEST>",
    "cross-env": "7.0.3",
    "eslint": "8.4.1",
    "jest": "27.4.4",
    "npm-run-all": "4.1.5",
    "prettier": "2.5.1",
    "rimraf": "3.0.2",
    "rollup": "2.78.1",
    "ts-jest": "27.1.1",
    "ts-node": "10.4.0",
    "tsconfig-paths": "3.12.0",
    "typescript": "4.5.3"
  }
}
"
`;

exports[`new-tokenizer not a monorepo block: src/index.ts 1`] = `
"export { match as wawMatch } from './match'
export { parse as wawParse } from './parse'
export { WawTokenizer, WawTokenizer as default } from './tokenizer'
export { uniqueName as WawTokenizerName } from './types'
export type {
  IThis as IWawHookContext,
  IToken as IWawToken,
  ITokenizerProps as IWawTokenizerProps,
} from './types'
"
`;

exports[`new-tokenizer not a monorepo block: src/match.ts 1`] = `
"import { AsciiCodePoint, isLineEnding } from '@yozora/character'
import type {
  IMatchBlockHookCreator,
  IPhrasingContentLine,
  // IResultOfEatAndInterruptPreviousSibling,
  // IResultOfEatContinuationText,
  // IResultOfEatLazyContinuationText,
  IResultOfEatOpener,
  IYastBlockToken,
} from '@yozora/core-tokenizer'
import { calcEndYastNodePoint, calcStartYastNodePoint } from '@yozora/core-tokenizer'
import type { IThis, IToken, T } from './types'
import { WawType } from './types'

export const match: IMatchBlockHookCreator<T, IToken, IThis> = function (api) {
  return {
    isContainingBlock: false,
    eatOpener,
    // eatAndInterruptPreviousSibling,
    // eatContinuationText,
    // eatLazyContinuationText,
  }

  function eatOpener(
    line: Readonly<IPhrasingContentLine>,
    parentToken: Readonly<IYastBlockToken>,
  ): IResultOfEatOpener<T, IToken> {
    const { nodePoints, startIndex, endIndex, firstNonWhitespaceIndex } = line
    if (firstNonWhitespaceIndex + 3 >= endIndex) return null

    let i = firstNonWhitespaceIndex
    const marker = nodePoints[i].codePoint
    let c = marker
    if (
      marker !== AsciiCodePoint.QUESTION_MARK &&
      marker !== AsciiCodePoint.EXCLAMATION_MARK
    ) return null

    for (; i < endIndex; ++i) {
      c = nodePoints[i].codePoint
      if (c !== marker) break
    }
    if (i < endIndex && !isLineEnding(c)) return null

    const nextIndex = endIndex
    const token: IToken = {
      nodeType: WawType,
      position: {
        start: calcStartYastNodePoint(nodePoints, startIndex),
        end: calcEndYastNodePoint(nodePoints, nextIndex - 1),
      },
      marker,
      continuous: true,
      children: [],
    }

    return { token, nextIndex, saturated: true }
  }

  // function eatAndInterruptPreviousSibling(
  //   line: Readonly<IPhrasingContentLine>,
  //   prevSiblingToken: Readonly<IYastBlockToken>,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatAndInterruptPreviousSibling<T, IToken> {
  //   const result = this.eatOpener(line, parentToken)
  //   if (result == null) return null
  //   return {
  //     token: result.token,
  //     nextIndex: result.nextIndex,
  //     remainingSibling: prevSiblingToken,
  //   }
  // }

  // function eatContinuationText(
  //   line: Readonly<IPhrasingContentLine>,
  //   token: IToken,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatContinuationText {
  //   return { status: 'notMatched' }
  // }

  // function eatLazyContinuationText(
  //   line: Readonly<IPhrasingContentLine>,
  //   token: IToken,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatLazyContinuationText {
  //   const result = this.eatContinuationText(line, token, parentToken)
  //   return result as IResultOfEatLazyContinuationText
  // }
}
"
`;

exports[`new-tokenizer not a monorepo block: src/parse.ts 1`] = `
"import type { Node } from '@yozora/ast'
import type { IParseBlockHookCreator } from '@yozora/core-tokenizer'
import type { INode, IThis, IToken, T } from './types'
import { WawType } from './types'

export const parse: IParseBlockHookCreator<T, IToken, INode, IThis> = function (api) {
  return {
    parse: tokens =>
      tokens.map(token => {
        const children: Node[] = api.parseBlockTokens(token.children)
        const node: INode = {
          type: WawType,
          position: token.position,
          children,
        }
        return node
      }),
  }
}
"
`;

exports[`new-tokenizer not a monorepo block: src/tokenizer.ts 1`] = `
"import type {
  IBlockTokenizer,
  IMatchBlockHookCreator,
  IParseBlockHookCreator,
} from '@yozora/core-tokenizer'
import { BaseBlockTokenizer, TokenizerPriority } from '@yozora/core-tokenizer'
import { match } from './match'
import { parse } from './parse'
import type { INode, IThis, IToken, ITokenizerProps, T } from './types'
import { uniqueName } from './types'

/**
 * Lexical Analyzer for Waw
 */
export class WawTokenizer
  extends BaseBlockTokenizer<T, IToken, INode, IThis>
  implements IBlockTokenizer<T, IToken, INode, IThis>
{
  /* istanbul ignore next */
  constructor(props: ITokenizerProps = {}) {
    super({
      name: props.name ?? uniqueName,
      priority: props.priority ?? TokenizerPriority.ATOMIC,
    })
  }

  public override readonly match: IMatchBlockHookCreator<T, IToken, IThis> = match

  public override readonly parse: IParseBlockHookCreator<T, IToken, INode, IThis> = parse
}
"
`;

exports[`new-tokenizer not a monorepo block: src/types.ts 1`] = `
"import type { Parent } from '@yozora/ast'
import type {
  IBaseBlockTokenizerProps,
  IPartialYastBlockToken,
  ITokenizer,
  IYastBlockToken,
} from '@yozora/core-tokenizer'

export const WawType = 'waw'
export type T = typeof WawType

export const uniqueName = '@yozora/tokenizer-waw'

export type INode = Parent<T>

export interface IToken extends IPartialYastBlockToken<T> {
  /**
   * CodePoint of '?' / '!'
   */
  marker: number
  /**
   * Whether there are no internal spaces between marker characters
   */
  continuous: boolean
  /**
   *
   */
  children: IYastBlockToken[]
}

export type IThis = ITokenizer

export type ITokenizerProps = Partial<IBaseBlockTokenizerProps>
"
`;

exports[`new-tokenizer not a monorepo block: tsconfig.json 1`] = `
"{
  "extends": "./tsconfig.settings",
  "compilerOptions": {
    "baseUrl": "."
  },
  "include": ["src", "script", "__test__"]
}
"
`;

exports[`new-tokenizer not a monorepo block: tsconfig.settings.json 1`] = `
"{
  "compilerOptions": {
    "allowSyntheticDefaultImports": true,
    "alwaysStrict": true,
    "declaration": true,
    "declarationMap": false,
    "downlevelIteration": true,
    "esModuleInterop": true,
    "experimentalDecorators": true,
    "forceConsistentCasingInFileNames": true,
    "lib": ["esnext"],
    "module": "esnext",
    "moduleResolution": "node",
    "newLine": "LF",
    "noEmit": false,
    "noEmitOnError": true,
    "noImplicitAny": true,
    "noImplicitOverride": true,
    "noImplicitReturns": false,
    "noImplicitThis": true,
    "noImplicitUseStrict": false,
    "noUnusedLocals": false,
    "noUnusedParameters": false,
    "pretty": false,
    "removeComments": false,
    "resolveJsonModule": true,
    "sourceMap": false,
    "strict": true,
    "strictFunctionTypes": true,
    "strictNullChecks": true,
    "strictPropertyInitialization": true,
    "suppressImplicitAnyIndexErrors": true,
    "target": "esnext"
  }
}
"
`;

exports[`new-tokenizer not a monorepo block: tsconfig.src.json 1`] = `
"{
  "extends": "./tsconfig.settings",
  "compilerOptions": {
    "rootDir": "src"
  },
  "include": ["src"]
}
"
`;

exports[`new-tokenizer not a monorepo default: console 1`] = `
[
  [
    "answers:",
    {
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "text",
      "isInlineTokenizer": true,
      "isMonorepo": false,
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "",
      "packageLocation": "yozora/tokenizer-inline-waw",
      "packageName": "@yozora/tokenizer-inline-waw",
      "packageUsage": "",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/tokenizer-inline-waw#readme",
      "repositoryName": "tokenizer-inline-waw",
      "tokenizerCategory": "inline",
      "tokenizerName": "inline-waw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "./tsconfig.settings",
      "tsconfigSrcExtends": "./tsconfig.settings",
    },
  ],
]
`;

exports[`new-tokenizer not a monorepo inline: .editorconfig 1`] = `
"root = true

[*]
charset = utf-8
indent_style = space
indent_size = 2
end_of_line = lf
insert_final_newline = true
tab_width = 2
trim_trailing_whitespace = true


[*.{md,mdx,hbs}]
insert_final_newline = false
trim_trailing_whitespace = false

[**/fixtures/**/*.json]
insert_final_newline = false
"
`;

exports[`new-tokenizer not a monorepo inline: .eslintrc 1`] = `
"{
  "root": true,
  "extends": ["@yozora"],
  "rules": {},
  "overrides": []
}
"
`;

exports[`new-tokenizer not a monorepo inline: .gitignore 1`] = `
".DS_Store

__tmp__/
lib/
build/
coverage/
dist/
node_modules/
release/
target/
**/*.styl.d.ts

*.tsbuildinfo
tmp/

# local env files
.env.local
.env.*.local

# Log files
npm-debug.log*
yarn-debug.log*
lerna-debug.log*
npm-error.log*
yarn-error.log*

# Editor directories and files
.idea/
.vscode/*
!.vscode/settings.json
!.vscode/launch.json

*.suo
*.ntvs*
*.njsproj
*.sln
*.sw*
"
`;

exports[`new-tokenizer not a monorepo inline: .prettierrc 1`] = `
"arrowParens: avoid
bracketSpacing: true
embeddedLanguageFormatting: off
endOfLine: lf
htmlWhitespaceSensitivity: strict
jsxBracketSameLine: false
jsxSingleQuote: false
printWidth: 80
proseWrap: always
quoteProps: as-needed
semi: false
singleQuote: true
trailingComma: all
useTabs: false
"
`;

exports[`new-tokenizer not a monorepo inline: __test__/answer.ts 1`] = `
"import { createTokenizerTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import InlineWawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new InlineWawTokenizer())

// Generate answers for custom test cases
void createTokenizerTester(parser)
  .scan('fixtures', __dirname)
  .runAnswer()
"
`;

exports[`new-tokenizer not a monorepo inline: __test__/fixtures/basic.json 1`] = `
"{
  "title": "",
  "cases": [
    {
      "description": "case#0",
      "input": "???????",
      "parseAnswer": {
        "type": "root",
        "children": [
          {
            "type": "paragraph",
            "children": [
              {
                "type": "inlineWaw",
                "value": "???????",
                "position": {
                  "start": {
                    "line": 1,
                    "column": 1,
                    "offset": 0
                  },
                  "end": {
                    "line": 1,
                    "column": 8,
                    "offset": 7
                  }
                }
              }
            ],
            "position": {
              "start": {
                "line": 1,
                "column": 1,
                "offset": 0
              },
              "end": {
                "line": 1,
                "column": 8,
                "offset": 7
              }
            }
          }
        ],
        "position": {
          "start": {
            "line": 1,
            "column": 1,
            "offset": 0
          },
          "end": {
            "line": 1,
            "column": 8,
            "offset": 7
          }
        }
      }
    }
  ]
}"
`;

exports[`new-tokenizer not a monorepo inline: __test__/inline-waw.spec.ts 1`] = `
"import { createTokenizerTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import InlineWawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new InlineWawTokenizer())

// Run official test cases
void createTokenizerTester(parser)
  .scan([
    'gfm/**/*.json',
    // The following cases are conflict when enabled GFM autolink (extension)
    // @see https://github.github.com/gfm/#example-616
    '!gfm/**/#616.json',
    '!gfm/**/#619.json',
    '!gfm/**/#620.json',
  ])
  .scan('custom')
  .runTest()

// Run custom test cases
void createTokenizerTester(parser)
  .scan('fixtures', __dirname)
  .runTest()
"
`;

exports[`new-tokenizer not a monorepo inline: README.md 1`] = `
"<header>
  <h1 align="center">
    <a href="https://github.com/guanghechen/tokenizer-inline-waw#readme">@yozora/tokenizer-inline-waw</a>
  </h1>
  <div align="center">
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-inline-waw">
      <img
        alt="Npm Version"
        src="https://img.shields.io/npm/v/@yozora/tokenizer-inline-waw.svg"
      />
    </a>
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-inline-waw">
      <img
        alt="Npm Download"
        src="https://img.shields.io/npm/dm/@yozora/tokenizer-inline-waw.svg"
      />
    </a>
    <a href="https://www.npmjs.com/package/@yozora/tokenizer-inline-waw">
      <img
        alt="Npm License"
        src="https://img.shields.io/npm/l/@yozora/tokenizer-inline-waw.svg"
      />
    </a>
    <a href="#install">
      <img
        alt="Module Formats: cjs, esm"
        src="https://img.shields.io/badge/module_formats-cjs%2C%20esm-green.svg"
      />
    </a>
    <a href="https://github.com/nodejs/node">
      <img
        alt="Node.js Version"
        src="https://img.shields.io/node/v/@yozora/tokenizer-inline-waw"
      />
    </a>
    <a href="https://github.com/yozorajs/yozora/blob/main/packages/core-tokenizer#readme">
      <img
        alt="Yozora Version"
        src="https://img.shields.io/npm/dependency-version/@yozora/tokenizer-inline-waw/@yozora/core-tokenizer"
      />
    </a>
    <a href="https://github.com/prettier/prettier">
      <img
        alt="Code Style: prettier"
        src="https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square"
      />
    </a>
  </div>
</header>
<br/>


See [@yozora/tokenizer-inline-waw documentation](https://yozora.guanghechen.com/docs/package/@yozora/tokenizer-inline-waw) for details.

Some descriptions.

## Install

* npm

  \`\`\`bash
  npm install --save @yozora/tokenizer-inline-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

* yarn

  \`\`\`bash
  yarn add @yozora/tokenizer-inline-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

## Usage


## Related


[homepage]: https://github.com/guanghechen/tokenizer-inline-waw#readme
"
`;

exports[`new-tokenizer not a monorepo inline: console 1`] = `
[
  [
    "answers:",
    {
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "text",
      "isInlineTokenizer": true,
      "isMonorepo": false,
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "Some descriptions",
      "packageLocation": "tokenizers/inline-waw",
      "packageName": "@yozora/tokenizer-inline-waw",
      "packageUsage": "Some descriptions.",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/tokenizer-inline-waw#readme",
      "repositoryName": "tokenizer-inline-waw",
      "tokenizerCategory": "inline",
      "tokenizerName": "inlineWaw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "./tsconfig.settings",
      "tsconfigSrcExtends": "./tsconfig.settings",
    },
  ],
]
`;

exports[`new-tokenizer not a monorepo inline: jest.config.js 1`] = `
"const fs = require('fs')

module.exports = {
  bail: true,
  verbose: true,
  errorOnDeprecated: true,
  roots: ['src', '__test__']
    .filter(p => fs.existsSync(p))
    .map(p => \`<rootDir>/\${p}\`),
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  globals: {
    'ts-jest': {
      tsconfig: '<rootDir>/tsconfig.json',
    },
  },
  transform: {
    '^.+\\\\.tsx?$': 'ts-jest',
  },
  testURL: 'http://localhost/',
  testEnvironment: 'node',
  testRegex: '/(__test__)/[^/]+\\\\.spec\\\\.[jt]sx?$',
  testPathIgnorePatterns: ['/coverage/', '/lib/', '/node_modules/'],
  collectCoverage: false,
  coverageDirectory: '<rootDir>/coverage/',
  collectCoverageFrom: [
    '<rootDir>/src/*.{js,jsx,ts,tsx}',
    '<rootDir>/src/**/*.{js,jsx,ts,tsx}',
  ],
  coveragePathIgnorePatterns: [],
  coverageThreshold: {
    global: {
      branches: 50,
      functions: 80,
      lines: 80,
      statements: 60,
    },
  },
  coverageReporters: ['lcov', 'text', 'text-summary'],
}
"
`;

exports[`new-tokenizer not a monorepo inline: package.json 1`] = `
"{
  "name": "@yozora/tokenizer-inline-waw",
  "version": "<LATEST>",
  "author": {
    "name": "guanghechen",
    "url": "https://github.com/guanghechen/"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/guanghechen/tokenizer-inline-waw.git"
  },
  "homepage": "https://github.com/guanghechen/tokenizer-inline-waw#readme",
  "keywords": [],
  "type": "module",
  "exports": {
    "import": "./lib/esm/index.mjs",
    "require": "./lib/cjs/index.cjs"
  },
  "types": "lib/types/index.d.ts",
  "source": "src/index.ts",
  "license": "MIT",
  "engines": {
    "node": ">= 16.0.0"
  },
  "files": [
    "lib/",
    "src/",
    "package.json",
    "CHANGELOG.md",
    "LICENSE",
    "README.md"
  ],
  "scripts": {
    "build": "cross-env NODE_ENV=production rollup -c rollup.config.js",
    "format": "run-s format:lint:fix format:prettier",
    "format:prettier": "prettier --write .",
    "format:lint:fix": "eslint . --fix",
    "prebuild": "rimraf lib/ && tsc -p tsconfig.src.json --emitDeclarationOnly",
    "prepublishOnly": "cross-env ROLLUP_SHOULD_SOURCEMAP=false yarn build",
    "test": "cross-env TS_NODE_FILES=true jest --config jest.config.js --rootDir .",
    "test:update": "node -r ts-node/register -r tsconfig-paths/register __test__/answer.ts"
  },
  "dependencies": {
    "@yozora/ast": "^<LATEST>",
    "@yozora/character": "^<LATEST>",
    "@yozora/core-tokenizer": "^<LATEST>"
  },
  "devDependencies": {
    "@guanghechen/rollup-config": "^2.1.0",
    "@types/jest": "27.0.3",
    "@yozora/eslint-config": "^<LATEST>",
    "@yozora/jest-for-tokenizer": "^<LATEST>",
    "@yozora/parser": "^<LATEST>",
    "cross-env": "7.0.3",
    "eslint": "8.4.1",
    "jest": "27.4.4",
    "npm-run-all": "4.1.5",
    "prettier": "2.5.1",
    "rimraf": "3.0.2",
    "rollup": "2.78.1",
    "ts-jest": "27.1.1",
    "ts-node": "10.4.0",
    "tsconfig-paths": "3.12.0",
    "typescript": "4.5.3"
  }
}
"
`;

exports[`new-tokenizer not a monorepo inline: src/index.ts 1`] = `
"export { match as inlineWawMatch } from './match'
export { parse as inlineWawParse } from './parse'
export { InlineWawTokenizer, InlineWawTokenizer as default } from './tokenizer'
export { InlineWawType, uniqueName as InlineWawTokenizerName } from './types'
export type {
  INode as IInlineWaw,
  IThis as IInlineWawHookContext,
  IToken as IInlineWawToken,
  ITokenizerProps as IInlineWawTokenizerProps,
} from './types'
"
`;

exports[`new-tokenizer not a monorepo inline: src/match.ts 1`] = `
"import type { INodePoint } from '@yozora/character'
import { AsciiCodePoint } from '@yozora/character'
import type {
  IMatchInlineHookCreator,
  IResultOfProcessSingleDelimiter,
} from '@yozora/core-tokenizer'
import { eatOptionalWhitespaces, genFindDelimiter } from '@yozora/core-tokenizer'
import type { IDelimiter, IThis, IToken, T } from './types'
import { InlineWawType } from './types'

export const match: IMatchInlineHookCreator<T, IDelimiter, IToken, IThis> = function (api) {
  return {
    findDelimiter: () => genFindDelimiter<IDelimiter>(_findDelimiter),
    processSingleDelimiter,
  }

  function _findDelimiter(startIndex: number, endIndex: number): IDelimiter | null {
    const nodePoints: ReadonlyArray<INodePoint> = api.getNodePoints()
    let i = eatOptionalWhitespaces(nodePoints, startIndex, endIndex)
    if (i + 3 >= endIndex) return null

    const marker = nodePoints[i].codePoint
    let c = marker
    if (
      marker !== AsciiCodePoint.QUESTION_MARK &&
      marker !== AsciiCodePoint.EXCLAMATION_MARK
    ) return null

    for (; i < endIndex; ++i) {
      c = nodePoints[i].codePoint
      if (c !== marker) break
    }
    if (i < endIndex) return null

    const delimiter: IDelimiter = {
      type: 'full',
      startIndex,
      endIndex,
    }
    return delimiter
  }

  function processSingleDelimiter(
    delimiter: IDelimiter
  ): IResultOfProcessSingleDelimiter<T, IToken> {
    if (delimiter.type !== 'full') return []
    const token: IToken = {
      nodeType: InlineWawType,
      startIndex: delimiter.startIndex,
      endIndex: delimiter.endIndex,
    }
    return [token]
  }
}
"
`;

exports[`new-tokenizer not a monorepo inline: src/parse.ts 1`] = `
"import type { Node } from '@yozora/ast'
import type { INodePoint } from '@yozora/character'
import { calcEscapedStringFromNodePoints } from '@yozora/character'
import type { IParseInlineHookCreator } from '@yozora/core-tokenizer'
import type { INode, IThis, IToken, T } from './types'
import { InlineWawType } from './types'

export const parse: IParseInlineHookCreator<T, IToken, INode, IThis> = function (api) {
  return {
    parse: tokens =>
      tokens.map(token => {
        const nodePoints: ReadonlyArray<INodePoint> = api.getNodePoints()
        const { startIndex, endIndex } = token
        let value: string = calcEscapedStringFromNodePoints(
          nodePoints,
          startIndex,
          endIndex
        )

        // Remove the spaces at the end of the line and beginning of the next line.
        value = value.replace(/[^\\S\\n]*\\n[^\\S\\n]*/g, '\\n')
        const children: Node[] = api.parseInlineTokens(token.children)
        const node: INode = {
          type: InlineWawType,
          position: api.calcPosition(token),
          value,
        }
        return node
      }),
  }
}
"
`;

exports[`new-tokenizer not a monorepo inline: src/tokenizer.ts 1`] = `
"import type {
  IInlineTokenizer,
  IMatchInlineHookCreator,
  IParseInlineHookCreator,
} from '@yozora/core-tokenizer'
import { BaseInlineTokenizer, TokenizerPriority } from '@yozora/core-tokenizer'
import { match } from './match'
import { parse } from './parse'
import type { IDelimiter, INode, IThis, IToken, ITokenizerProps, T } from './types'
import { uniqueName } from './types'

/**
 * Lexical Analyzer for InlineWaw
 */
export class InlineWawTokenizer
  extends BaseInlineTokenizer<T, IDelimiter, IToken, INode, IThis>
  implements IInlineTokenizer<T, IDelimiter, IToken, INode, IThis> {

  /* istanbul ignore next */
  constructor(props: ITokenizerProps = {}) {
    super({
      name: props.name ?? uniqueName,
      priority: props.priority ?? TokenizerPriority.ATOMIC,
    })
  }

  public override readonly match: IMatchInlineHookCreator<T, IDelimiter, IToken, IThis> = match

  public override readonly parse: IParseInlineHookCreator<T, IToken, INode, IThis> = parse
}
"
`;

exports[`new-tokenizer not a monorepo inline: src/types.ts 1`] = `
"import type { Literal } from '@yozora/ast'
import type {
  IBaseInlineTokenizerProps,
  IPartialYastInlineToken,
  ITokenizer,
  IYastTokenDelimiter,
} from '@yozora/core-tokenizer'

export const InlineWawType = 'inlineWaw'
export type T = typeof InlineWawType

export const uniqueName = '@yozora/tokenizer-inline-waw'

/**
 *
 * @example
 *    \`\`\`\`markdown
 *    \`\`\`\`
 *    ===>
 *    \`\`\`js
 *    \`\`\`
 */
export type INode = Literal<T>

export type IToken = IPartialYastInlineToken<T>

export type IDelimiter = IYastTokenDelimiter

export type IThis = ITokenizer

export type ITokenizerProps = Partial<IBaseInlineTokenizerProps>
"
`;

exports[`new-tokenizer not a monorepo inline: tsconfig.json 1`] = `
"{
  "extends": "./tsconfig.settings",
  "compilerOptions": {
    "baseUrl": "."
  },
  "include": ["src", "script", "__test__"]
}
"
`;

exports[`new-tokenizer not a monorepo inline: tsconfig.settings.json 1`] = `
"{
  "compilerOptions": {
    "allowSyntheticDefaultImports": true,
    "alwaysStrict": true,
    "declaration": true,
    "declarationMap": false,
    "downlevelIteration": true,
    "esModuleInterop": true,
    "experimentalDecorators": true,
    "forceConsistentCasingInFileNames": true,
    "lib": ["esnext"],
    "module": "esnext",
    "moduleResolution": "node",
    "newLine": "LF",
    "noEmit": false,
    "noEmitOnError": true,
    "noImplicitAny": true,
    "noImplicitOverride": true,
    "noImplicitReturns": false,
    "noImplicitThis": true,
    "noImplicitUseStrict": false,
    "noUnusedLocals": false,
    "noUnusedParameters": false,
    "pretty": false,
    "removeComments": false,
    "resolveJsonModule": true,
    "sourceMap": false,
    "strict": true,
    "strictFunctionTypes": true,
    "strictNullChecks": true,
    "strictPropertyInitialization": true,
    "suppressImplicitAnyIndexErrors": true,
    "target": "esnext"
  }
}
"
`;

exports[`new-tokenizer not a monorepo inline: tsconfig.src.json 1`] = `
"{
  "extends": "./tsconfig.settings",
  "compilerOptions": {
    "rootDir": "src"
  },
  "include": ["src"]
}
"
`;
