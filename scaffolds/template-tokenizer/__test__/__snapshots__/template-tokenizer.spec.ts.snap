// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`new-tokenizer monorepo block: __test__/answer.ts 1`] = `
"import { createTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import WawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new WawTokenizer())

// Generate answers for custom test cases
createTester(parser)
  .scan('fixtures', __dirname)
  .runAnswer()
"
`;

exports[`new-tokenizer monorepo block: __test__/fixtures/basic.json 1`] = `
"{
  \\"title\\": \\"\\",
  \\"cases\\": [
    {
      \\"description\\": \\"case#0\\",
      \\"input\\": \\"???????\\",
      \\"parseAnswer\\": {
        \\"type\\": \\"root\\",
        \\"children\\": [
          {
            \\"type\\": \\"thematicBreak\\",
            \\"position\\": {
              \\"start\\": {
                \\"line\\": 1,
                \\"column\\": 1,
                \\"offset\\": 0
              },
              \\"end\\": {
                \\"line\\": 1,
                \\"column\\": 8,
                \\"offset\\": 7
              }
            }
          }
        ],
        \\"position\\": {
          \\"start\\": {
            \\"line\\": 1,
            \\"column\\": 1,
            \\"offset\\": 0
          },
          \\"end\\": {
            \\"line\\": 1,
            \\"column\\": 8,
            \\"offset\\": 7
          }
        }
      }
    }
  ]
}"
`;

exports[`new-tokenizer monorepo block: __test__/waw.spec.ts 1`] = `
"import { createTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import WawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new WawTokenizer())

// Run official test cases
createTester(parser)
  .scan([
    'gfm/**/*.json',
    // The following cases are conflict when enabled GFM autolink (extension)
    // @see https://github.github.com/gfm/#example-616
    '!gfm/**/#616.json',
    '!gfm/**/#619.json',
    '!gfm/**/#620.json',
  ])
  .scan('custom')
  .runTest()

// Run custom test cases
createTester(parser)
  .scan('fixtures', __dirname)
  .runTest()
"
`;

exports[`new-tokenizer monorepo block: README.md 1`] = `
"<header>
  <h1 align=\\"center\\">
    <a href=\\"https://github.com/guanghechen/yozora/tree/main/tokenizers/waw#readme\\">@yozora/tokenizer-waw</a>
  </h1>
  <div align=\\"center\\">
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-waw\\">
      <img
        alt=\\"Npm Version\\"
        src=\\"https://img.shields.io/npm/v/@yozora/tokenizer-waw.svg\\"
      />
    </a>
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-waw\\">
      <img
        alt=\\"Npm Download\\"
        src=\\"https://img.shields.io/npm/dm/@yozora/tokenizer-waw.svg\\"
      />
    </a>
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-waw\\">
      <img
        alt=\\"Npm License\\"
        src=\\"https://img.shields.io/npm/l/@yozora/tokenizer-waw.svg\\"
      />
    </a>
    <a href=\\"#install\\">
      <img
        alt=\\"Module Formats: cjs, esm\\"
        src=\\"https://img.shields.io/badge/module_formats-cjs%2C%20esm-green.svg\\"
      />
    </a>
    <a href=\\"https://github.com/nodejs/node\\">
      <img
        alt=\\"Node.js Version\\"
        src=\\"https://img.shields.io/node/v/@yozora/tokenizer-waw\\"
      />
    </a>
    <a href=\\"https://github.com/yozorajs/yozora/blob/main/packages/core-tokenizer#readme\\">
      <img
        alt=\\"Yozora Version\\"
        src=\\"https://img.shields.io/npm/dependency-version/@yozora/tokenizer-waw/@yozora/core-tokenizer\\"
      />
    </a>
    <a href=\\"https://github.com/prettier/prettier\\">
      <img
        alt=\\"Code Style: prettier\\"
        src=\\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\\"
      />
    </a>
  </div>
</header>
<br/>


See [@yozora/tokenizer-waw documentation](https://yozora.guanghechen.com/docs/package/@yozora/tokenizer-waw) for details.

Some descriptions.

## Install

* npm

  \`\`\`bash
  npm install --save @yozora/tokenizer-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

* yarn

  \`\`\`bash
  yarn add @yozora/tokenizer-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

## Usage


## Related


[homepage]: https://github.com/guanghechen/yozora/tree/main/tokenizers/waw#readme
"
`;

exports[`new-tokenizer monorepo block: console 1`] = `
Array [
  Array [
    "answers:",
    Object {
      "BlockTokenizerPostParsePhaseHook__isNotLastHook": false,
      "IMatchBlockHook__isNotLastHook": false,
      "IParseBlockHook__isNotLastHook": false,
      "IPostMatchBlockHook__isNotLastHook": false,
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "paragraph",
      "isBlockTokenizer": true,
      "isMonorepo": true,
      "lastHook": "IParseBlockHook",
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "Some descriptions",
      "packageLocation": "tokenizers/waw",
      "packageName": "@yozora/tokenizer-waw",
      "packageUsage": "Some descriptions.",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/yozora/tree/main/tokenizers/waw#readme",
      "repositoryName": "yozora",
      "tokenizerCategory": "block",
      "tokenizerName": "waw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "../../tsconfig",
      "tsconfigSrcExtends": "../../tsconfig.settings",
      "useTokenizerMatchBlockHook": true,
      "useTokenizerParseBlockHook": true,
      "useTokenizerPostMatchBlockHook": false,
      "usingHooks": false,
    },
  ],
]
`;

exports[`new-tokenizer monorepo block: package.json 1`] = `
"{
  \\"name\\": \\"@yozora/tokenizer-waw\\",
  \\"version\\": \\"<LATEST>\\",
  \\"author\\": {
    \\"name\\": \\"guanghechen\\",
    \\"url\\": \\"https://github.com/guanghechen/\\"
  },
  \\"repository\\": {
    \\"type\\": \\"git\\",
    \\"url\\": \\"https://github.com/guanghechen/yozora.git\\",
    \\"directory\\": \\"tokenizers/waw\\"
  },
  \\"homepage\\": \\"https://github.com/guanghechen/yozora/tree/main/tokenizers/waw#readme\\",
  \\"keywords\\": [],
  \\"main\\": \\"lib/cjs/index.js\\",
  \\"module\\": \\"lib/esm/index.js\\",
  \\"types\\": \\"lib/types/index.d.ts\\",
  \\"source\\": \\"src/index.ts\\",
  \\"license\\": \\"MIT\\",
  \\"engines\\": {
    \\"node\\": \\">= 14.15.0\\"
  },
  \\"files\\": [
    \\"lib/\\",
    \\"!lib/**/*.js.map\\",
    \\"!lib/**/*.d.ts.map\\",
    \\"package.json\\",
    \\"CHANGELOG.md\\",
    \\"LICENSE\\",
    \\"README.md\\"
  ],
  \\"scripts\\": {
    \\"build\\": \\"cross-env NODE_ENV=production rollup -c ../../rollup.config.js\\",
    \\"prebuild\\": \\"rimraf lib/ && tsc -p tsconfig.src.json --emitDeclarationOnly\\",
    \\"prepublishOnly\\": \\"cross-env ROLLUP_SHOULD_SOURCEMAP=false yarn build\\",
    \\"test\\": \\"cross-env TS_NODE_FILES=true jest --config ../../jest.config.js --rootDir .\\",
    \\"test:update\\": \\"node -r ts-node/register -r tsconfig-paths/register __test__/answer.ts\\"
  },
  \\"dependencies\\": {
    \\"@yozora/ast\\": \\"^<LATEST>\\",
    \\"@yozora/character\\": \\"^<LATEST>\\",
    \\"@yozora/core-tokenizer\\": \\"^<LATEST>\\"
  },
  \\"devDependencies\\": {
    \\"@yozora/core-tokenizer\\": \\"^<LATEST>\\",
    \\"@yozora/eslint-config\\": \\"^<LATEST>\\",
    \\"@yozora/jest-for-tokenizer\\": \\"^<LATEST>\\",
    \\"@yozora/parser\\": \\"^<LATEST>\\",
    \\"tsconfig-paths\\": \\"3.9.0\\",
    \\"typescript\\": \\"4.3.5\\"
  }
}
"
`;

exports[`new-tokenizer monorepo block: src/index.ts 1`] = `
"export { WawTokenizer, WawTokenizer as default } from './tokenizer'
export { uniqueName as WawTokenizerName } from './types'
export type {
  IToken as IWawIToken,
  ITokenizerProps as IWawITokenizerProps,
} from './types'
"
`;

exports[`new-tokenizer monorepo block: src/tokenizer.ts 1`] = `
"import type { IYastNode } from '@yozora/ast'
import { ThematicBreakType } from '@yozora/ast'
import { AsciiCodePoint, isLineEnding } from '@yozora/character'
import type {
  IPhrasingContentLine,
  IPostMatchBlockPhaseApi,
  IResultOfEatAndInterruptPreviousSibling,
  IResultOfEatContinuationText,
  IResultOfEatLazyContinuationText,
  IResultOfEatOpener,
  IResultOfParse,
  ITokenizer,
  IMatchBlockHook,
  IParseBlockHook,
  IPostMatchBlockHook,
  IYastBlockToken,
} from '@yozora/core-tokenizer'
import {
  BaseBlockTokenizer,
  TokenizerPriority,
  calcEndYastNodePoint,
  calcStartYastNodePoint,
} from '@yozora/core-tokenizer'
import type { INode, IToken, ITokenizerProps, T } from './types'
import { uniqueName } from './types'

/**
 * Lexical Analyzer for Waw
 */
export class WawTokenizer
  extends BaseBlockTokenizer
  implements
    ITokenizer
    IMatchBlockHook<T, IToken>
    IParseBlockHook<T, IToken, INode>
 {
  public readonly isContainingBlock = false

  /* istanbul ignore next */
  constructor(props: ITokenizerProps = {}) {
    super({
      name: props.name ?? uniqueName,
      priority: props.priority ?? TokenizerPriority.ATOMIC,
    })
  }

  /**
   * @override
   * @see IMatchBlockHook
   */
  public eatOpener(
    line: Readonly<IPhrasingContentLine>,
    parentToken: Readonly<IYastBlockToken>,
  ): IResultOfEatOpener<T, IToken> {
    const { nodePoints, startIndex, endIndex, firstNonWhitespaceIndex } = line
    if (firstNonWhitespaceIndex + 3 >= endIndex) return null

    let i = firstNonWhitespaceIndex
    const marker = nodePoints[i].codePoint
    let c = marker
    if (
      marker !== AsciiCodePoint.QUESTION_MARK &&
      marker !== AsciiCodePoint.EXCLAMATION_MARK
    ) return null

    for (; i < endIndex; ++i) {
      c = nodePoints[i].codePoint
      if (c !== marker) break
    }
    if (i < endIndex && !isLineEnding(c)) return null

    const nextIndex = endIndex
    const token: IToken = {
      nodeType: ThematicBreakType,
      position: {
        start: calcStartYastNodePoint(nodePoints, startIndex),
        end: calcEndYastNodePoint(nodePoints, nextIndex - 1),
      },
      marker,
      continuous: true,
    }

    return { token, nextIndex, saturated: true }
  }

  // /**
  //  * @override
  //  * @see IMatchBlockHook
  //  */
  // public eatAndInterruptPreviousSibling(
  //   line: Readonly<IPhrasingContentLine>,
  //   prevSiblingToken: Readonly<IYastBlockToken>,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatAndInterruptPreviousSibling<T, IToken> {
  //   const result = this.eatOpener(line, parentToken)
  //   if (result == null) return null
  //   return {
  //     token: result.token,
  //     nextIndex: result.nextIndex,
  //     remainingSibling: prevSiblingToken,
  //   }
  // }

  // /**
  //  * @override
  //  * @see IMatchBlockHook
  //  */
  // public eatContinuationText(
  //   line: Readonly<IPhrasingContentLine>,
  //   token: IToken,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatContinuationText {
  //   return { status: 'notMatched' }
  // }

  // /**
  //  * @override
  //  * @see IMatchBlockHook
  //  */
  // public eatLazyContinuationText(
  //   line: Readonly<IPhrasingContentLine>,
  //   token: IToken,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatLazyContinuationText {
  //   const result = this.eatContinuationText(line, token, parentToken)
  //   return result as IResultOfEatLazyContinuationText
  // }

  /**
   * @override
   * @see IParseBlockHook
   */
  public parseBlock(token: Readonly<IToken>): IResultOfParse<T, INode> {
    const node: INode = { type: token.nodeType }
    return node
  }
}
"
`;

exports[`new-tokenizer monorepo block: src/types.ts 1`] = `
"import type { IThematicBreak, ThematicBreakType } from '@yozora/ast'
import type {
  IBaseBlockTokenizerProps,
  IPartialYastBlockToken,
} from '@yozora/core-tokenizer'

export type T = ThematicBreakType
export type INode = IThematicBreak

export const uniqueName = '@yozora/tokenizer-waw'


export interface IToken extends IPartialYastBlockToken<T> {
  /**
   * CodePoint of '?' / '!'
   */
  marker: number
  /**
   * Whether there are no internal spaces between marker characters
   */
  continuous: boolean
}


export type ITokenizerProps = Partial<IBaseBlockTokenizerProps>
"
`;

exports[`new-tokenizer monorepo block: tsconfig.json 1`] = `
"{
  \\"extends\\": \\"../../tsconfig\\",
  \\"compilerOptions\\": {
    \\"baseUrl\\": \\".\\"
  },
  \\"include\\": [\\"src\\", \\"script\\", \\"__test__\\"]
}
"
`;

exports[`new-tokenizer monorepo block: tsconfig.src.json 1`] = `
"{
  \\"extends\\": \\"../../tsconfig.settings\\",
  \\"compilerOptions\\": {
    \\"declarationDir\\": \\"lib/types\\",
    \\"rootDir\\": \\"src\\"
  },
  \\"include\\": [\\"src\\"]
}
"
`;

exports[`new-tokenizer monorepo default: console 1`] = `
Array [
  Array [
    "answers:",
    Object {
      "BlockTokenizerPostParsePhaseHook__isNotLastHook": false,
      "IMatchBlockHook__isNotLastHook": false,
      "IParseBlockHook__isNotLastHook": false,
      "IPostMatchBlockHook__isNotLastHook": false,
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "text",
      "isInlineTokenizer": true,
      "isMonorepo": true,
      "lastHook": "IParseBlockHook",
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "",
      "packageLocation": "packages/tokenizer-inline-waw",
      "packageName": "@yozora/tokenizer-inline-waw",
      "packageUsage": "",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/yozora/tree/main/packages/tokenizer-inline-waw#readme",
      "repositoryName": "yozora",
      "tokenizerCategory": "inline",
      "tokenizerName": "inline-waw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "../../tsconfig",
      "tsconfigSrcExtends": "../../tsconfig.settings",
      "useTokenizerMatchBlockHook": true,
      "useTokenizerParseBlockHook": true,
      "useTokenizerPostMatchBlockHook": true,
      "usingHooks": false,
    },
  ],
]
`;

exports[`new-tokenizer monorepo inline: __test__/answer.ts 1`] = `
"import { createTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import InlineWawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new InlineWawTokenizer())

// Generate answers for custom test cases
createTester(parser)
  .scan('fixtures', __dirname)
  .runAnswer()
"
`;

exports[`new-tokenizer monorepo inline: __test__/fixtures/basic.json 1`] = `
"{
  \\"title\\": \\"\\",
  \\"cases\\": [
    {
      \\"description\\": \\"case#0\\",
      \\"input\\": \\"???????\\",
      \\"parseAnswer\\": {
        \\"type\\": \\"root\\",
        \\"children\\": [
          {
            \\"type\\": \\"paragraph\\",
            \\"children\\": [
              {
                \\"type\\": \\"inlineWaw\\",
                \\"value\\": \\"???????\\",
                \\"position\\": {
                  \\"start\\": {
                    \\"line\\": 1,
                    \\"column\\": 1,
                    \\"offset\\": 0
                  },
                  \\"end\\": {
                    \\"line\\": 1,
                    \\"column\\": 8,
                    \\"offset\\": 7
                  }
                }
              }
            ],
            \\"position\\": {
              \\"start\\": {
                \\"line\\": 1,
                \\"column\\": 1,
                \\"offset\\": 0
              },
              \\"end\\": {
                \\"line\\": 1,
                \\"column\\": 8,
                \\"offset\\": 7
              }
            }
          }
        ],
        \\"position\\": {
          \\"start\\": {
            \\"line\\": 1,
            \\"column\\": 1,
            \\"offset\\": 0
          },
          \\"end\\": {
            \\"line\\": 1,
            \\"column\\": 8,
            \\"offset\\": 7
          }
        }
      }
    }
  ]
}"
`;

exports[`new-tokenizer monorepo inline: __test__/inline-waw.spec.ts 1`] = `
"import { createTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import InlineWawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new InlineWawTokenizer())

// Run official test cases
createTester(parser)
  .scan([
    'gfm/**/*.json',
    // The following cases are conflict when enabled GFM autolink (extension)
    // @see https://github.github.com/gfm/#example-616
    '!gfm/**/#616.json',
    '!gfm/**/#619.json',
    '!gfm/**/#620.json',
  ])
  .scan('custom')
  .runTest()

// Run custom test cases
createTester(parser)
  .scan('fixtures', __dirname)
  .runTest()
"
`;

exports[`new-tokenizer monorepo inline: README.md 1`] = `
"<header>
  <h1 align=\\"center\\">
    <a href=\\"https://github.com/guanghechen/yozora/tree/main/tokenizers/inline-waw#readme\\">@yozora/tokenizer-inline-waw</a>
  </h1>
  <div align=\\"center\\">
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-inline-waw\\">
      <img
        alt=\\"Npm Version\\"
        src=\\"https://img.shields.io/npm/v/@yozora/tokenizer-inline-waw.svg\\"
      />
    </a>
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-inline-waw\\">
      <img
        alt=\\"Npm Download\\"
        src=\\"https://img.shields.io/npm/dm/@yozora/tokenizer-inline-waw.svg\\"
      />
    </a>
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-inline-waw\\">
      <img
        alt=\\"Npm License\\"
        src=\\"https://img.shields.io/npm/l/@yozora/tokenizer-inline-waw.svg\\"
      />
    </a>
    <a href=\\"#install\\">
      <img
        alt=\\"Module Formats: cjs, esm\\"
        src=\\"https://img.shields.io/badge/module_formats-cjs%2C%20esm-green.svg\\"
      />
    </a>
    <a href=\\"https://github.com/nodejs/node\\">
      <img
        alt=\\"Node.js Version\\"
        src=\\"https://img.shields.io/node/v/@yozora/tokenizer-inline-waw\\"
      />
    </a>
    <a href=\\"https://github.com/yozorajs/yozora/blob/main/packages/core-tokenizer#readme\\">
      <img
        alt=\\"Yozora Version\\"
        src=\\"https://img.shields.io/npm/dependency-version/@yozora/tokenizer-inline-waw/@yozora/core-tokenizer\\"
      />
    </a>
    <a href=\\"https://github.com/prettier/prettier\\">
      <img
        alt=\\"Code Style: prettier\\"
        src=\\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\\"
      />
    </a>
  </div>
</header>
<br/>


See [@yozora/tokenizer-inline-waw documentation](https://yozora.guanghechen.com/docs/package/@yozora/tokenizer-inline-waw) for details.

Some descriptions.

## Install

* npm

  \`\`\`bash
  npm install --save @yozora/tokenizer-inline-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

* yarn

  \`\`\`bash
  yarn add @yozora/tokenizer-inline-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

## Usage


## Related


[homepage]: https://github.com/guanghechen/yozora/tree/main/tokenizers/inline-waw#readme
"
`;

exports[`new-tokenizer monorepo inline: console 1`] = `
Array [
  Array [
    "answers:",
    Object {
      "BlockTokenizerPostParsePhaseHook__isNotLastHook": false,
      "IMatchBlockHook__isNotLastHook": false,
      "IParseBlockHook__isNotLastHook": false,
      "IPostMatchBlockHook__isNotLastHook": false,
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "text",
      "isInlineTokenizer": true,
      "isMonorepo": true,
      "lastHook": "IParseBlockHook",
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "Some descriptions",
      "packageLocation": "tokenizers/inline-waw",
      "packageName": "@yozora/tokenizer-inline-waw",
      "packageUsage": "Some descriptions.",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/yozora/tree/main/tokenizers/inline-waw#readme",
      "repositoryName": "yozora",
      "tokenizerCategory": "inline",
      "tokenizerName": "inlineWaw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "../../tsconfig",
      "tsconfigSrcExtends": "../../tsconfig.settings",
      "useTokenizerMatchBlockHook": true,
      "useTokenizerParseBlockHook": true,
      "useTokenizerPostMatchBlockHook": true,
      "usingHooks": false,
    },
  ],
]
`;

exports[`new-tokenizer monorepo inline: package.json 1`] = `
"{
  \\"name\\": \\"@yozora/tokenizer-inline-waw\\",
  \\"version\\": \\"<LATEST>\\",
  \\"author\\": {
    \\"name\\": \\"guanghechen\\",
    \\"url\\": \\"https://github.com/guanghechen/\\"
  },
  \\"repository\\": {
    \\"type\\": \\"git\\",
    \\"url\\": \\"https://github.com/guanghechen/yozora.git\\",
    \\"directory\\": \\"tokenizers/inline-waw\\"
  },
  \\"homepage\\": \\"https://github.com/guanghechen/yozora/tree/main/tokenizers/inline-waw#readme\\",
  \\"keywords\\": [],
  \\"main\\": \\"lib/cjs/index.js\\",
  \\"module\\": \\"lib/esm/index.js\\",
  \\"types\\": \\"lib/types/index.d.ts\\",
  \\"source\\": \\"src/index.ts\\",
  \\"license\\": \\"MIT\\",
  \\"engines\\": {
    \\"node\\": \\">= 14.15.0\\"
  },
  \\"files\\": [
    \\"lib/\\",
    \\"!lib/**/*.js.map\\",
    \\"!lib/**/*.d.ts.map\\",
    \\"package.json\\",
    \\"CHANGELOG.md\\",
    \\"LICENSE\\",
    \\"README.md\\"
  ],
  \\"scripts\\": {
    \\"build\\": \\"cross-env NODE_ENV=production rollup -c ../../rollup.config.js\\",
    \\"prebuild\\": \\"rimraf lib/ && tsc -p tsconfig.src.json --emitDeclarationOnly\\",
    \\"prepublishOnly\\": \\"cross-env ROLLUP_SHOULD_SOURCEMAP=false yarn build\\",
    \\"test\\": \\"cross-env TS_NODE_FILES=true jest --config ../../jest.config.js --rootDir .\\",
    \\"test:update\\": \\"node -r ts-node/register -r tsconfig-paths/register __test__/answer.ts\\"
  },
  \\"dependencies\\": {
    \\"@yozora/ast\\": \\"^<LATEST>\\",
    \\"@yozora/character\\": \\"^<LATEST>\\",
    \\"@yozora/core-tokenizer\\": \\"^<LATEST>\\"
  },
  \\"devDependencies\\": {
    \\"@yozora/core-tokenizer\\": \\"^<LATEST>\\",
    \\"@yozora/eslint-config\\": \\"^<LATEST>\\",
    \\"@yozora/jest-for-tokenizer\\": \\"^<LATEST>\\",
    \\"@yozora/parser\\": \\"^<LATEST>\\",
    \\"tsconfig-paths\\": \\"3.9.0\\",
    \\"typescript\\": \\"4.3.5\\"
  }
}
"
`;

exports[`new-tokenizer monorepo inline: src/index.ts 1`] = `
"export { InlineWawTokenizer, InlineWawTokenizer as default } from './tokenizer'
export { uniqueName as InlineWawTokenizerName } from './types'
export type {
  InlineWawType,
  Node as IInlineWaw,
  IToken as IInlineWawIToken,
  ITokenizerProps as IInlineWawITokenizerProps,
} from './types'
"
`;

exports[`new-tokenizer monorepo inline: src/tokenizer.ts 1`] = `
"import type { IYastNode } from '@yozora/ast'
import type { INodePoint } from '@yozora/character'
import { AsciiCodePoint } from '@yozora/character'
import { calcEscapedStringFromNodePoints } from '@yozora/character'
import type {
  IMatchInlinePhaseApi,
  IParseInlinePhaseApi,
  IResultOfProcessSingleDelimiter,
  ITokenizer,
  IMatchInlineHook,
  IParseInlineHook,
} from '@yozora/core-tokenizer'
import {
  BaseInlineTokenizer,
  TokenizerPriority,
  eatOptionalWhitespaces,
} from '@yozora/core-tokenizer'
import type { IDelimiter, INode, IToken, ITokenizerProps, T } from './types'
import { InlineWawType, uniqueName } from './types'

/**
 * Lexical Analyzer for InlineWaw
 */
export class InlineWawTokenizer
  extends BaseInlineTokenizer<T, IDelimiter, IToken, INode>
  implements
    ITokenizer,
    IMatchInlineHook<T, IDelimiter, IToken>,
    IParseInlineHook<T, IToken, INode> {

  /* istanbul ignore next */
  constructor(props: ITokenizerProps = {}) {
    super({
      name: props.name ?? uniqueName,
      priority: props.priority ?? TokenizerPriority.ATOMIC,
    })
  }

  /**
   * @override
   * @see BaseInlineTokenizer
   */
  protected override _findDelimiter(
    startIndex: number,
    endIndex: number,
    api: Readonly<IMatchInlinePhaseApi>,
  ): IDelimiter | null {
    const nodePoints: ReadonlyArray<INodePoint> = api.getNodePoints()
    let i = eatOptionalWhitespaces(nodePoints, startIndex, endIndex)
    if (i + 3 >= endIndex) return null

    const marker = nodePoints[i].codePoint
    let c = marker
    if (
      marker !== AsciiCodePoint.QUESTION_MARK &&
      marker !== AsciiCodePoint.EXCLAMATION_MARK
    ) return null

    for (; i < endIndex; ++i) {
      c = nodePoints[i].codePoint
      if (c !== marker) break
    }
    if (i < endIndex) return null

    const delimiter: IDelimiter = {
      type: 'full',
      startIndex,
      endIndex,
    }
    return delimiter
  }

  /**
   * @override
   * @see IMatchInlineHook
   */
  public processSingleDelimiter(
    delimiter: IDelimiter,
    api: Readonly<IMatchInlinePhaseApi>,
  ): IResultOfProcessSingleDelimiter<T, IToken> {
    if (delimiter.type !== 'full') return []
    const token: IToken = {
      nodeType: InlineWawType,
      startIndex: delimiter.startIndex,
      endIndex: delimiter.endIndex,
    }
    return [token]
  }

  /**
   * @override
   * @see IParseInlineHook
   */
  public processToken(
    token: IToken,
    children: IYastNode[],
    api: Readonly<IParseInlinePhaseApi>,
  ): INode {
    const nodePoints: ReadonlyArray<INodePoint> = api.getNodePoints()
    const { startIndex, endIndex } = token
    let value: string = calcEscapedStringFromNodePoints(
      nodePoints,
      startIndex,
      endIndex
    )

    // Remove the spaces at the end of the line and beginning of the next line.
    value = value.replace(/[^\\\\S\\\\n]*\\\\n[^\\\\S\\\\n]*/g, '\\\\n')
    const node: INode = { type: InlineWawType, value }
    return node
  }
}
"
`;

exports[`new-tokenizer monorepo inline: src/types.ts 1`] = `
"import type { IYastLiteral } from '@yozora/ast'
import type {
  IBaseInlineTokenizerProps,
  IPartialYastInlineToken,
  IYastTokenDelimiter,
} from '@yozora/core-tokenizer'

export const InlineWawType = 'inlineWaw'
export type T = typeof InlineWawType

export const uniqueName = '@yozora/tokenizer-inline-waw'

/**
 *
 * @example
 *    \`\`\`\`markdown
 *    \`\`\`\`
 *    ===>
 *    \`\`\`js
 *    \`\`\`
 */
export interface INode extends IYastLiteral<T> {

}

export type IToken = IPartialYastInlineToken<T>

export type IDelimiter = IYastTokenDelimiter

export type ITokenizerProps = Partial<IBaseInlineTokenizerProps>
"
`;

exports[`new-tokenizer monorepo inline: tsconfig.json 1`] = `
"{
  \\"extends\\": \\"../../tsconfig\\",
  \\"compilerOptions\\": {
    \\"baseUrl\\": \\".\\"
  },
  \\"include\\": [\\"src\\", \\"script\\", \\"__test__\\"]
}
"
`;

exports[`new-tokenizer monorepo inline: tsconfig.src.json 1`] = `
"{
  \\"extends\\": \\"../../tsconfig.settings\\",
  \\"compilerOptions\\": {
    \\"declarationDir\\": \\"lib/types\\",
    \\"rootDir\\": \\"src\\"
  },
  \\"include\\": [\\"src\\"]
}
"
`;

exports[`new-tokenizer not a monorepo block: .editorconfig 1`] = `
"root = true

[*]
charset = utf-8
indent_style = space
indent_size = 2
end_of_line = lf
insert_final_newline = true
tab_width = 2
trim_trailing_whitespace = true


[*.{md,mdx,hbs}]
insert_final_newline = false
trim_trailing_whitespace = false

[**/fixtures/**/*.json]
insert_final_newline = false
"
`;

exports[`new-tokenizer not a monorepo block: .eslintrc 1`] = `
"{
  \\"root\\": true,
  \\"extends\\": [\\"@yozora\\"],
  \\"rules\\": {},
  \\"overrides\\": []
}
"
`;

exports[`new-tokenizer not a monorepo block: .gitignore 1`] = `
".DS_Store

__tmp__/
lib/
build/
coverage/
dist/
node_modules/
release/
target/
**/*.styl.d.ts

*.tsbuildinfo
tmp/

# local env files
.env.local
.env.*.local

# Log files
npm-debug.log*
yarn-debug.log*
lerna-debug.log*
npm-error.log*
yarn-error.log*

# Editor directories and files
.idea/
.vscode/*
!.vscode/settings.json
!.vscode/launch.json

*.suo
*.ntvs*
*.njsproj
*.sln
*.sw*
"
`;

exports[`new-tokenizer not a monorepo block: .prettierrc 1`] = `
"arrowParens: avoid
bracketSpacing: true
embeddedLanguageFormatting: off
endOfLine: lf
htmlWhitespaceSensitivity: strict
jsxBracketSameLine: false
jsxSingleQuote: false
printWidth: 80
proseWrap: always
quoteProps: as-needed
semi: false
singleQuote: true
trailingComma: all
useTabs: false
"
`;

exports[`new-tokenizer not a monorepo block: __test__/answer.ts 1`] = `
"import { createTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import WawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new WawTokenizer())

// Generate answers for custom test cases
createTester(parser)
  .scan('fixtures', __dirname)
  .runAnswer()
"
`;

exports[`new-tokenizer not a monorepo block: __test__/fixtures/basic.json 1`] = `
"{
  \\"title\\": \\"\\",
  \\"cases\\": [
    {
      \\"description\\": \\"case#0\\",
      \\"input\\": \\"???????\\",
      \\"parseAnswer\\": {
        \\"type\\": \\"root\\",
        \\"children\\": [
          {
            \\"type\\": \\"thematicBreak\\",
            \\"position\\": {
              \\"start\\": {
                \\"line\\": 1,
                \\"column\\": 1,
                \\"offset\\": 0
              },
              \\"end\\": {
                \\"line\\": 1,
                \\"column\\": 8,
                \\"offset\\": 7
              }
            }
          }
        ],
        \\"position\\": {
          \\"start\\": {
            \\"line\\": 1,
            \\"column\\": 1,
            \\"offset\\": 0
          },
          \\"end\\": {
            \\"line\\": 1,
            \\"column\\": 8,
            \\"offset\\": 7
          }
        }
      }
    }
  ]
}"
`;

exports[`new-tokenizer not a monorepo block: __test__/waw.spec.ts 1`] = `
"import { createTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import WawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new WawTokenizer())

// Run official test cases
createTester(parser)
  .scan([
    'gfm/**/*.json',
    // The following cases are conflict when enabled GFM autolink (extension)
    // @see https://github.github.com/gfm/#example-616
    '!gfm/**/#616.json',
    '!gfm/**/#619.json',
    '!gfm/**/#620.json',
  ])
  .scan('custom')
  .runTest()

// Run custom test cases
createTester(parser)
  .scan('fixtures', __dirname)
  .runTest()
"
`;

exports[`new-tokenizer not a monorepo block: README.md 1`] = `
"<header>
  <h1 align=\\"center\\">
    <a href=\\"https://github.com/guanghechen/tokenizer-waw#readme\\">@yozora/tokenizer-waw</a>
  </h1>
  <div align=\\"center\\">
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-waw\\">
      <img
        alt=\\"Npm Version\\"
        src=\\"https://img.shields.io/npm/v/@yozora/tokenizer-waw.svg\\"
      />
    </a>
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-waw\\">
      <img
        alt=\\"Npm Download\\"
        src=\\"https://img.shields.io/npm/dm/@yozora/tokenizer-waw.svg\\"
      />
    </a>
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-waw\\">
      <img
        alt=\\"Npm License\\"
        src=\\"https://img.shields.io/npm/l/@yozora/tokenizer-waw.svg\\"
      />
    </a>
    <a href=\\"#install\\">
      <img
        alt=\\"Module Formats: cjs, esm\\"
        src=\\"https://img.shields.io/badge/module_formats-cjs%2C%20esm-green.svg\\"
      />
    </a>
    <a href=\\"https://github.com/nodejs/node\\">
      <img
        alt=\\"Node.js Version\\"
        src=\\"https://img.shields.io/node/v/@yozora/tokenizer-waw\\"
      />
    </a>
    <a href=\\"https://github.com/yozorajs/yozora/blob/main/packages/core-tokenizer#readme\\">
      <img
        alt=\\"Yozora Version\\"
        src=\\"https://img.shields.io/npm/dependency-version/@yozora/tokenizer-waw/@yozora/core-tokenizer\\"
      />
    </a>
    <a href=\\"https://github.com/prettier/prettier\\">
      <img
        alt=\\"Code Style: prettier\\"
        src=\\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\\"
      />
    </a>
  </div>
</header>
<br/>


See [@yozora/tokenizer-waw documentation](https://yozora.guanghechen.com/docs/package/@yozora/tokenizer-waw) for details.

Some descriptions.

## Install

* npm

  \`\`\`bash
  npm install --save @yozora/tokenizer-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

* yarn

  \`\`\`bash
  yarn add @yozora/tokenizer-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

## Usage


## Related


[homepage]: https://github.com/guanghechen/tokenizer-waw#readme
"
`;

exports[`new-tokenizer not a monorepo block: console 1`] = `
Array [
  Array [
    "answers:",
    Object {
      "BlockTokenizerPostParsePhaseHook__isNotLastHook": false,
      "IMatchBlockHook__isNotLastHook": false,
      "IParseBlockHook__isNotLastHook": false,
      "IPostMatchBlockHook__isNotLastHook": false,
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "paragraph",
      "isBlockTokenizer": true,
      "isMonorepo": false,
      "lastHook": "IParseBlockHook",
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "Some descriptions",
      "packageLocation": "tokenizers/waw",
      "packageName": "@yozora/tokenizer-waw",
      "packageUsage": "Some descriptions.",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/tokenizer-waw#readme",
      "repositoryName": "tokenizer-waw",
      "tokenizerCategory": "block",
      "tokenizerName": "waw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "./tsconfig.settings",
      "tsconfigSrcExtends": "./tsconfig.settings",
      "useTokenizerMatchBlockHook": true,
      "useTokenizerParseBlockHook": true,
      "useTokenizerPostMatchBlockHook": false,
      "usingHooks": false,
    },
  ],
]
`;

exports[`new-tokenizer not a monorepo block: jest.config.js 1`] = `
"const fs = require('fs')

module.exports = {
  bail: true,
  verbose: true,
  errorOnDeprecated: true,
  roots: ['src', '__test__']
    .filter(p => fs.existsSync(p))
    .map(p => \`<rootDir>/\${p}\`),
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  globals: {
    'ts-jest': {
      tsconfig: '<rootDir>/tsconfig.json',
    },
  },
  transform: {
    '^.+\\\\\\\\.tsx?$': 'ts-jest',
  },
  testURL: 'http://localhost/',
  testEnvironment: 'node',
  testRegex: '/(__test__)/[^/]+\\\\\\\\.spec\\\\\\\\.[jt]sx?$',
  testPathIgnorePatterns: ['/coverage/', '/lib/', '/node_modules/'],
  collectCoverage: false,
  coverageDirectory: '<rootDir>/coverage/',
  collectCoverageFrom: [
    '<rootDir>/src/*.{js,jsx,ts,tsx}',
    '<rootDir>/src/**/*.{js,jsx,ts,tsx}',
  ],
  coveragePathIgnorePatterns: [],
  coverageThreshold: {
    global: {
      branches: 50,
      functions: 80,
      lines: 80,
      statements: 60,
    },
  },
  coverageReporters: ['lcov', 'text', 'text-summary'],
}
"
`;

exports[`new-tokenizer not a monorepo block: package.json 1`] = `
"{
  \\"name\\": \\"@yozora/tokenizer-waw\\",
  \\"version\\": \\"<LATEST>\\",
  \\"author\\": {
    \\"name\\": \\"guanghechen\\",
    \\"url\\": \\"https://github.com/guanghechen/\\"
  },
  \\"repository\\": {
    \\"type\\": \\"git\\",
    \\"url\\": \\"https://github.com/guanghechen/tokenizer-waw.git\\"
  },
  \\"homepage\\": \\"https://github.com/guanghechen/tokenizer-waw#readme\\",
  \\"keywords\\": [],
  \\"main\\": \\"lib/cjs/index.js\\",
  \\"module\\": \\"lib/esm/index.js\\",
  \\"types\\": \\"lib/types/index.d.ts\\",
  \\"source\\": \\"src/index.ts\\",
  \\"license\\": \\"MIT\\",
  \\"engines\\": {
    \\"node\\": \\">= 14.15.0\\"
  },
  \\"files\\": [
    \\"lib/\\",
    \\"!lib/**/*.js.map\\",
    \\"!lib/**/*.d.ts.map\\",
    \\"package.json\\",
    \\"CHANGELOG.md\\",
    \\"LICENSE\\",
    \\"README.md\\"
  ],
  \\"scripts\\": {
    \\"build\\": \\"cross-env NODE_ENV=production rollup -c rollup.config.js\\",
    \\"format\\": \\"run-s format:lint:fix format:prettier\\",
    \\"format:prettier\\": \\"prettier --write .\\",
    \\"format:lint:fix\\": \\"eslint . --fix\\",
    \\"prebuild\\": \\"rimraf lib/ && tsc -p tsconfig.src.json --emitDeclarationOnly\\",
    \\"prepublishOnly\\": \\"cross-env ROLLUP_SHOULD_SOURCEMAP=false yarn build\\",
    \\"test\\": \\"cross-env TS_NODE_FILES=true jest --config jest.config.js --rootDir .\\",
    \\"test:update\\": \\"node -r ts-node/register -r tsconfig-paths/register __test__/answer.ts\\"
  },
  \\"dependencies\\": {
    \\"@yozora/ast\\": \\"^<LATEST>\\",
    \\"@yozora/character\\": \\"^<LATEST>\\",
    \\"@yozora/core-tokenizer\\": \\"^<LATEST>\\"
  },
  \\"devDependencies\\": {
    \\"@guanghechen/rollup-config\\": \\"^1.7.1\\",
    \\"@types/jest\\": \\"26.0.24\\",
    \\"@yozora/core-tokenizer\\": \\"^<LATEST>\\",
    \\"@yozora/eslint-config\\": \\"^<LATEST>\\",
    \\"@yozora/jest-for-tokenizer\\": \\"^<LATEST>\\",
    \\"@yozora/parser\\": \\"^<LATEST>\\",
    \\"cross-env\\": \\"7.0.3\\",
    \\"eslint\\": \\"7.30.0\\",
    \\"jest\\": \\"27.0.6\\",
    \\"npm-run-all\\": \\"4.1.5\\",
    \\"prettier\\": \\"2.3.2\\",
    \\"rimraf\\": \\"3.0.2\\",
    \\"rollup\\": \\"^2.52.7\\",
    \\"ts-jest\\": \\"27.0.3\\",
    \\"ts-node\\": \\"10.0.0\\",
    \\"tsconfig-paths\\": \\"3.9.0\\",
    \\"typescript\\": \\"4.3.5\\"
  }
}
"
`;

exports[`new-tokenizer not a monorepo block: src/index.ts 1`] = `
"export { WawTokenizer, WawTokenizer as default } from './tokenizer'
export { uniqueName as WawTokenizerName } from './types'
export type {
  IToken as IWawIToken,
  ITokenizerProps as IWawITokenizerProps,
} from './types'
"
`;

exports[`new-tokenizer not a monorepo block: src/tokenizer.ts 1`] = `
"import type { IYastNode } from '@yozora/ast'
import { ThematicBreakType } from '@yozora/ast'
import { AsciiCodePoint, isLineEnding } from '@yozora/character'
import type {
  IPhrasingContentLine,
  IPostMatchBlockPhaseApi,
  IResultOfEatAndInterruptPreviousSibling,
  IResultOfEatContinuationText,
  IResultOfEatLazyContinuationText,
  IResultOfEatOpener,
  IResultOfParse,
  ITokenizer,
  IMatchBlockHook,
  IParseBlockHook,
  IPostMatchBlockHook,
  IYastBlockToken,
} from '@yozora/core-tokenizer'
import {
  BaseBlockTokenizer,
  TokenizerPriority,
  calcEndYastNodePoint,
  calcStartYastNodePoint,
} from '@yozora/core-tokenizer'
import type { INode, IToken, ITokenizerProps, T } from './types'
import { uniqueName } from './types'

/**
 * Lexical Analyzer for Waw
 */
export class WawTokenizer
  extends BaseBlockTokenizer
  implements
    ITokenizer
    IMatchBlockHook<T, IToken>
    IParseBlockHook<T, IToken, INode>
 {
  public readonly isContainingBlock = false

  /* istanbul ignore next */
  constructor(props: ITokenizerProps = {}) {
    super({
      name: props.name ?? uniqueName,
      priority: props.priority ?? TokenizerPriority.ATOMIC,
    })
  }

  /**
   * @override
   * @see IMatchBlockHook
   */
  public eatOpener(
    line: Readonly<IPhrasingContentLine>,
    parentToken: Readonly<IYastBlockToken>,
  ): IResultOfEatOpener<T, IToken> {
    const { nodePoints, startIndex, endIndex, firstNonWhitespaceIndex } = line
    if (firstNonWhitespaceIndex + 3 >= endIndex) return null

    let i = firstNonWhitespaceIndex
    const marker = nodePoints[i].codePoint
    let c = marker
    if (
      marker !== AsciiCodePoint.QUESTION_MARK &&
      marker !== AsciiCodePoint.EXCLAMATION_MARK
    ) return null

    for (; i < endIndex; ++i) {
      c = nodePoints[i].codePoint
      if (c !== marker) break
    }
    if (i < endIndex && !isLineEnding(c)) return null

    const nextIndex = endIndex
    const token: IToken = {
      nodeType: ThematicBreakType,
      position: {
        start: calcStartYastNodePoint(nodePoints, startIndex),
        end: calcEndYastNodePoint(nodePoints, nextIndex - 1),
      },
      marker,
      continuous: true,
    }

    return { token, nextIndex, saturated: true }
  }

  // /**
  //  * @override
  //  * @see IMatchBlockHook
  //  */
  // public eatAndInterruptPreviousSibling(
  //   line: Readonly<IPhrasingContentLine>,
  //   prevSiblingToken: Readonly<IYastBlockToken>,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatAndInterruptPreviousSibling<T, IToken> {
  //   const result = this.eatOpener(line, parentToken)
  //   if (result == null) return null
  //   return {
  //     token: result.token,
  //     nextIndex: result.nextIndex,
  //     remainingSibling: prevSiblingToken,
  //   }
  // }

  // /**
  //  * @override
  //  * @see IMatchBlockHook
  //  */
  // public eatContinuationText(
  //   line: Readonly<IPhrasingContentLine>,
  //   token: IToken,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatContinuationText {
  //   return { status: 'notMatched' }
  // }

  // /**
  //  * @override
  //  * @see IMatchBlockHook
  //  */
  // public eatLazyContinuationText(
  //   line: Readonly<IPhrasingContentLine>,
  //   token: IToken,
  //   parentToken: Readonly<IYastBlockToken>,
  // ): IResultOfEatLazyContinuationText {
  //   const result = this.eatContinuationText(line, token, parentToken)
  //   return result as IResultOfEatLazyContinuationText
  // }

  /**
   * @override
   * @see IParseBlockHook
   */
  public parseBlock(token: Readonly<IToken>): IResultOfParse<T, INode> {
    const node: INode = { type: token.nodeType }
    return node
  }
}
"
`;

exports[`new-tokenizer not a monorepo block: src/types.ts 1`] = `
"import type { IThematicBreak, ThematicBreakType } from '@yozora/ast'
import type {
  IBaseBlockTokenizerProps,
  IPartialYastBlockToken,
} from '@yozora/core-tokenizer'

export type T = ThematicBreakType
export type INode = IThematicBreak

export const uniqueName = '@yozora/tokenizer-waw'


export interface IToken extends IPartialYastBlockToken<T> {
  /**
   * CodePoint of '?' / '!'
   */
  marker: number
  /**
   * Whether there are no internal spaces between marker characters
   */
  continuous: boolean
}


export type ITokenizerProps = Partial<IBaseBlockTokenizerProps>
"
`;

exports[`new-tokenizer not a monorepo block: tsconfig.json 1`] = `
"{
  \\"extends\\": \\"./tsconfig.settings\\",
  \\"compilerOptions\\": {
    \\"baseUrl\\": \\".\\"
  },
  \\"include\\": [\\"src\\", \\"script\\", \\"__test__\\"]
}
"
`;

exports[`new-tokenizer not a monorepo block: tsconfig.settings.json 1`] = `
"{
  \\"compilerOptions\\": {
    \\"allowSyntheticDefaultImports\\": true,
    \\"alwaysStrict\\": true,
    \\"declaration\\": true,
    \\"declarationMap\\": false,
    \\"downlevelIteration\\": true,
    \\"esModuleInterop\\": true,
    \\"experimentalDecorators\\": true,
    \\"forceConsistentCasingInFileNames\\": true,
    \\"lib\\": [\\"esnext\\"],
    \\"moduleResolution\\": \\"node\\",
    \\"newLine\\": \\"LF\\",
    \\"noEmit\\": false,
    \\"noEmitOnError\\": true,
    \\"noImplicitAny\\": true,
    \\"noImplicitOverride\\": true,
    \\"noImplicitReturns\\": false,
    \\"noImplicitThis\\": true,
    \\"noImplicitUseStrict\\": false,
    \\"noUnusedLocals\\": false,
    \\"noUnusedParameters\\": false,
    \\"pretty\\": false,
    \\"removeComments\\": false,
    \\"resolveJsonModule\\": true,
    \\"sourceMap\\": false,
    \\"strict\\": true,
    \\"strictFunctionTypes\\": true,
    \\"strictNullChecks\\": true,
    \\"strictPropertyInitialization\\": true,
    \\"suppressImplicitAnyIndexErrors\\": true,
    \\"target\\": \\"es2015\\"
  }
}
"
`;

exports[`new-tokenizer not a monorepo block: tsconfig.src.json 1`] = `
"{
  \\"extends\\": \\"./tsconfig.settings\\",
  \\"compilerOptions\\": {
    \\"declarationDir\\": \\"lib/types\\",
    \\"rootDir\\": \\"src\\"
  },
  \\"include\\": [\\"src\\"]
}
"
`;

exports[`new-tokenizer not a monorepo default: console 1`] = `
Array [
  Array [
    "answers:",
    Object {
      "BlockTokenizerPostParsePhaseHook__isNotLastHook": false,
      "IMatchBlockHook__isNotLastHook": false,
      "IParseBlockHook__isNotLastHook": false,
      "IPostMatchBlockHook__isNotLastHook": false,
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "text",
      "isInlineTokenizer": true,
      "isMonorepo": false,
      "lastHook": "IParseBlockHook",
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "",
      "packageLocation": "yozora/tokenizer-inline-waw",
      "packageName": "@yozora/tokenizer-inline-waw",
      "packageUsage": "",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/tokenizer-inline-waw#readme",
      "repositoryName": "tokenizer-inline-waw",
      "tokenizerCategory": "inline",
      "tokenizerName": "inline-waw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "./tsconfig.settings",
      "tsconfigSrcExtends": "./tsconfig.settings",
      "useTokenizerMatchBlockHook": true,
      "useTokenizerParseBlockHook": true,
      "useTokenizerPostMatchBlockHook": true,
      "usingHooks": false,
    },
  ],
]
`;

exports[`new-tokenizer not a monorepo inline: .editorconfig 1`] = `
"root = true

[*]
charset = utf-8
indent_style = space
indent_size = 2
end_of_line = lf
insert_final_newline = true
tab_width = 2
trim_trailing_whitespace = true


[*.{md,mdx,hbs}]
insert_final_newline = false
trim_trailing_whitespace = false

[**/fixtures/**/*.json]
insert_final_newline = false
"
`;

exports[`new-tokenizer not a monorepo inline: .eslintrc 1`] = `
"{
  \\"root\\": true,
  \\"extends\\": [\\"@yozora\\"],
  \\"rules\\": {},
  \\"overrides\\": []
}
"
`;

exports[`new-tokenizer not a monorepo inline: .gitignore 1`] = `
".DS_Store

__tmp__/
lib/
build/
coverage/
dist/
node_modules/
release/
target/
**/*.styl.d.ts

*.tsbuildinfo
tmp/

# local env files
.env.local
.env.*.local

# Log files
npm-debug.log*
yarn-debug.log*
lerna-debug.log*
npm-error.log*
yarn-error.log*

# Editor directories and files
.idea/
.vscode/*
!.vscode/settings.json
!.vscode/launch.json

*.suo
*.ntvs*
*.njsproj
*.sln
*.sw*
"
`;

exports[`new-tokenizer not a monorepo inline: .prettierrc 1`] = `
"arrowParens: avoid
bracketSpacing: true
embeddedLanguageFormatting: off
endOfLine: lf
htmlWhitespaceSensitivity: strict
jsxBracketSameLine: false
jsxSingleQuote: false
printWidth: 80
proseWrap: always
quoteProps: as-needed
semi: false
singleQuote: true
trailingComma: all
useTabs: false
"
`;

exports[`new-tokenizer not a monorepo inline: __test__/answer.ts 1`] = `
"import { createTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import InlineWawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new InlineWawTokenizer())

// Generate answers for custom test cases
createTester(parser)
  .scan('fixtures', __dirname)
  .runAnswer()
"
`;

exports[`new-tokenizer not a monorepo inline: __test__/fixtures/basic.json 1`] = `
"{
  \\"title\\": \\"\\",
  \\"cases\\": [
    {
      \\"description\\": \\"case#0\\",
      \\"input\\": \\"???????\\",
      \\"parseAnswer\\": {
        \\"type\\": \\"root\\",
        \\"children\\": [
          {
            \\"type\\": \\"paragraph\\",
            \\"children\\": [
              {
                \\"type\\": \\"inlineWaw\\",
                \\"value\\": \\"???????\\",
                \\"position\\": {
                  \\"start\\": {
                    \\"line\\": 1,
                    \\"column\\": 1,
                    \\"offset\\": 0
                  },
                  \\"end\\": {
                    \\"line\\": 1,
                    \\"column\\": 8,
                    \\"offset\\": 7
                  }
                }
              }
            ],
            \\"position\\": {
              \\"start\\": {
                \\"line\\": 1,
                \\"column\\": 1,
                \\"offset\\": 0
              },
              \\"end\\": {
                \\"line\\": 1,
                \\"column\\": 8,
                \\"offset\\": 7
              }
            }
          }
        ],
        \\"position\\": {
          \\"start\\": {
            \\"line\\": 1,
            \\"column\\": 1,
            \\"offset\\": 0
          },
          \\"end\\": {
            \\"line\\": 1,
            \\"column\\": 8,
            \\"offset\\": 7
          }
        }
      }
    }
  ]
}"
`;

exports[`new-tokenizer not a monorepo inline: __test__/inline-waw.spec.ts 1`] = `
"import { createTester } from '@yozora/jest-for-tokenizer'
import YozoraParser from '@yozora/parser'
import InlineWawTokenizer from '../src'

const parser = new YozoraParser({
  defaultParseOptions: {
    shouldReservePosition: true
  }
})
  .useTokenizer(new InlineWawTokenizer())

// Run official test cases
createTester(parser)
  .scan([
    'gfm/**/*.json',
    // The following cases are conflict when enabled GFM autolink (extension)
    // @see https://github.github.com/gfm/#example-616
    '!gfm/**/#616.json',
    '!gfm/**/#619.json',
    '!gfm/**/#620.json',
  ])
  .scan('custom')
  .runTest()

// Run custom test cases
createTester(parser)
  .scan('fixtures', __dirname)
  .runTest()
"
`;

exports[`new-tokenizer not a monorepo inline: README.md 1`] = `
"<header>
  <h1 align=\\"center\\">
    <a href=\\"https://github.com/guanghechen/tokenizer-inline-waw#readme\\">@yozora/tokenizer-inline-waw</a>
  </h1>
  <div align=\\"center\\">
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-inline-waw\\">
      <img
        alt=\\"Npm Version\\"
        src=\\"https://img.shields.io/npm/v/@yozora/tokenizer-inline-waw.svg\\"
      />
    </a>
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-inline-waw\\">
      <img
        alt=\\"Npm Download\\"
        src=\\"https://img.shields.io/npm/dm/@yozora/tokenizer-inline-waw.svg\\"
      />
    </a>
    <a href=\\"https://www.npmjs.com/package/@yozora/tokenizer-inline-waw\\">
      <img
        alt=\\"Npm License\\"
        src=\\"https://img.shields.io/npm/l/@yozora/tokenizer-inline-waw.svg\\"
      />
    </a>
    <a href=\\"#install\\">
      <img
        alt=\\"Module Formats: cjs, esm\\"
        src=\\"https://img.shields.io/badge/module_formats-cjs%2C%20esm-green.svg\\"
      />
    </a>
    <a href=\\"https://github.com/nodejs/node\\">
      <img
        alt=\\"Node.js Version\\"
        src=\\"https://img.shields.io/node/v/@yozora/tokenizer-inline-waw\\"
      />
    </a>
    <a href=\\"https://github.com/yozorajs/yozora/blob/main/packages/core-tokenizer#readme\\">
      <img
        alt=\\"Yozora Version\\"
        src=\\"https://img.shields.io/npm/dependency-version/@yozora/tokenizer-inline-waw/@yozora/core-tokenizer\\"
      />
    </a>
    <a href=\\"https://github.com/prettier/prettier\\">
      <img
        alt=\\"Code Style: prettier\\"
        src=\\"https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square\\"
      />
    </a>
  </div>
</header>
<br/>


See [@yozora/tokenizer-inline-waw documentation](https://yozora.guanghechen.com/docs/package/@yozora/tokenizer-inline-waw) for details.

Some descriptions.

## Install

* npm

  \`\`\`bash
  npm install --save @yozora/tokenizer-inline-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

* yarn

  \`\`\`bash
  yarn add @yozora/tokenizer-inline-waw @yozora/core-tokenizer @yozora/character
  \`\`\`

## Usage


## Related


[homepage]: https://github.com/guanghechen/tokenizer-inline-waw#readme
"
`;

exports[`new-tokenizer not a monorepo inline: console 1`] = `
Array [
  Array [
    "answers:",
    Object {
      "BlockTokenizerPostParsePhaseHook__isNotLastHook": false,
      "IMatchBlockHook__isNotLastHook": false,
      "IParseBlockHook__isNotLastHook": false,
      "IPostMatchBlockHook__isNotLastHook": false,
      "cwd": "<WORKSPACE>/output",
      "fallbackTokenizerName": "text",
      "isInlineTokenizer": true,
      "isMonorepo": false,
      "lastHook": "IParseBlockHook",
      "nodeModulesPath": "../../node_modules",
      "packageAuthor": "guanghechen",
      "packageDescription": "Some descriptions",
      "packageLocation": "tokenizers/inline-waw",
      "packageName": "@yozora/tokenizer-inline-waw",
      "packageUsage": "Some descriptions.",
      "packageVersion": "<LATEST>",
      "repositoryHomepage": "https://github.com/guanghechen/tokenizer-inline-waw#readme",
      "repositoryName": "tokenizer-inline-waw",
      "tokenizerCategory": "inline",
      "tokenizerName": "inlineWaw",
      "toolPackageVersion": "<LATEST>",
      "tsconfigExtends": "./tsconfig.settings",
      "tsconfigSrcExtends": "./tsconfig.settings",
      "useTokenizerMatchBlockHook": true,
      "useTokenizerParseBlockHook": true,
      "useTokenizerPostMatchBlockHook": true,
      "usingHooks": false,
    },
  ],
]
`;

exports[`new-tokenizer not a monorepo inline: jest.config.js 1`] = `
"const fs = require('fs')

module.exports = {
  bail: true,
  verbose: true,
  errorOnDeprecated: true,
  roots: ['src', '__test__']
    .filter(p => fs.existsSync(p))
    .map(p => \`<rootDir>/\${p}\`),
  moduleFileExtensions: ['ts', 'tsx', 'js', 'jsx', 'json', 'node'],
  globals: {
    'ts-jest': {
      tsconfig: '<rootDir>/tsconfig.json',
    },
  },
  transform: {
    '^.+\\\\\\\\.tsx?$': 'ts-jest',
  },
  testURL: 'http://localhost/',
  testEnvironment: 'node',
  testRegex: '/(__test__)/[^/]+\\\\\\\\.spec\\\\\\\\.[jt]sx?$',
  testPathIgnorePatterns: ['/coverage/', '/lib/', '/node_modules/'],
  collectCoverage: false,
  coverageDirectory: '<rootDir>/coverage/',
  collectCoverageFrom: [
    '<rootDir>/src/*.{js,jsx,ts,tsx}',
    '<rootDir>/src/**/*.{js,jsx,ts,tsx}',
  ],
  coveragePathIgnorePatterns: [],
  coverageThreshold: {
    global: {
      branches: 50,
      functions: 80,
      lines: 80,
      statements: 60,
    },
  },
  coverageReporters: ['lcov', 'text', 'text-summary'],
}
"
`;

exports[`new-tokenizer not a monorepo inline: package.json 1`] = `
"{
  \\"name\\": \\"@yozora/tokenizer-inline-waw\\",
  \\"version\\": \\"<LATEST>\\",
  \\"author\\": {
    \\"name\\": \\"guanghechen\\",
    \\"url\\": \\"https://github.com/guanghechen/\\"
  },
  \\"repository\\": {
    \\"type\\": \\"git\\",
    \\"url\\": \\"https://github.com/guanghechen/tokenizer-inline-waw.git\\"
  },
  \\"homepage\\": \\"https://github.com/guanghechen/tokenizer-inline-waw#readme\\",
  \\"keywords\\": [],
  \\"main\\": \\"lib/cjs/index.js\\",
  \\"module\\": \\"lib/esm/index.js\\",
  \\"types\\": \\"lib/types/index.d.ts\\",
  \\"source\\": \\"src/index.ts\\",
  \\"license\\": \\"MIT\\",
  \\"engines\\": {
    \\"node\\": \\">= 14.15.0\\"
  },
  \\"files\\": [
    \\"lib/\\",
    \\"!lib/**/*.js.map\\",
    \\"!lib/**/*.d.ts.map\\",
    \\"package.json\\",
    \\"CHANGELOG.md\\",
    \\"LICENSE\\",
    \\"README.md\\"
  ],
  \\"scripts\\": {
    \\"build\\": \\"cross-env NODE_ENV=production rollup -c rollup.config.js\\",
    \\"format\\": \\"run-s format:lint:fix format:prettier\\",
    \\"format:prettier\\": \\"prettier --write .\\",
    \\"format:lint:fix\\": \\"eslint . --fix\\",
    \\"prebuild\\": \\"rimraf lib/ && tsc -p tsconfig.src.json --emitDeclarationOnly\\",
    \\"prepublishOnly\\": \\"cross-env ROLLUP_SHOULD_SOURCEMAP=false yarn build\\",
    \\"test\\": \\"cross-env TS_NODE_FILES=true jest --config jest.config.js --rootDir .\\",
    \\"test:update\\": \\"node -r ts-node/register -r tsconfig-paths/register __test__/answer.ts\\"
  },
  \\"dependencies\\": {
    \\"@yozora/ast\\": \\"^<LATEST>\\",
    \\"@yozora/character\\": \\"^<LATEST>\\",
    \\"@yozora/core-tokenizer\\": \\"^<LATEST>\\"
  },
  \\"devDependencies\\": {
    \\"@guanghechen/rollup-config\\": \\"^1.7.1\\",
    \\"@types/jest\\": \\"26.0.24\\",
    \\"@yozora/core-tokenizer\\": \\"^<LATEST>\\",
    \\"@yozora/eslint-config\\": \\"^<LATEST>\\",
    \\"@yozora/jest-for-tokenizer\\": \\"^<LATEST>\\",
    \\"@yozora/parser\\": \\"^<LATEST>\\",
    \\"cross-env\\": \\"7.0.3\\",
    \\"eslint\\": \\"7.30.0\\",
    \\"jest\\": \\"27.0.6\\",
    \\"npm-run-all\\": \\"4.1.5\\",
    \\"prettier\\": \\"2.3.2\\",
    \\"rimraf\\": \\"3.0.2\\",
    \\"rollup\\": \\"^2.52.7\\",
    \\"ts-jest\\": \\"27.0.3\\",
    \\"ts-node\\": \\"10.0.0\\",
    \\"tsconfig-paths\\": \\"3.9.0\\",
    \\"typescript\\": \\"4.3.5\\"
  }
}
"
`;

exports[`new-tokenizer not a monorepo inline: src/index.ts 1`] = `
"export { InlineWawTokenizer, InlineWawTokenizer as default } from './tokenizer'
export { uniqueName as InlineWawTokenizerName } from './types'
export type {
  InlineWawType,
  Node as IInlineWaw,
  IToken as IInlineWawIToken,
  ITokenizerProps as IInlineWawITokenizerProps,
} from './types'
"
`;

exports[`new-tokenizer not a monorepo inline: src/tokenizer.ts 1`] = `
"import type { IYastNode } from '@yozora/ast'
import type { INodePoint } from '@yozora/character'
import { AsciiCodePoint } from '@yozora/character'
import { calcEscapedStringFromNodePoints } from '@yozora/character'
import type {
  IMatchInlinePhaseApi,
  IParseInlinePhaseApi,
  IResultOfProcessSingleDelimiter,
  ITokenizer,
  IMatchInlineHook,
  IParseInlineHook,
} from '@yozora/core-tokenizer'
import {
  BaseInlineTokenizer,
  TokenizerPriority,
  eatOptionalWhitespaces,
} from '@yozora/core-tokenizer'
import type { IDelimiter, INode, IToken, ITokenizerProps, T } from './types'
import { InlineWawType, uniqueName } from './types'

/**
 * Lexical Analyzer for InlineWaw
 */
export class InlineWawTokenizer
  extends BaseInlineTokenizer<T, IDelimiter, IToken, INode>
  implements
    ITokenizer,
    IMatchInlineHook<T, IDelimiter, IToken>,
    IParseInlineHook<T, IToken, INode> {

  /* istanbul ignore next */
  constructor(props: ITokenizerProps = {}) {
    super({
      name: props.name ?? uniqueName,
      priority: props.priority ?? TokenizerPriority.ATOMIC,
    })
  }

  /**
   * @override
   * @see BaseInlineTokenizer
   */
  protected override _findDelimiter(
    startIndex: number,
    endIndex: number,
    api: Readonly<IMatchInlinePhaseApi>,
  ): IDelimiter | null {
    const nodePoints: ReadonlyArray<INodePoint> = api.getNodePoints()
    let i = eatOptionalWhitespaces(nodePoints, startIndex, endIndex)
    if (i + 3 >= endIndex) return null

    const marker = nodePoints[i].codePoint
    let c = marker
    if (
      marker !== AsciiCodePoint.QUESTION_MARK &&
      marker !== AsciiCodePoint.EXCLAMATION_MARK
    ) return null

    for (; i < endIndex; ++i) {
      c = nodePoints[i].codePoint
      if (c !== marker) break
    }
    if (i < endIndex) return null

    const delimiter: IDelimiter = {
      type: 'full',
      startIndex,
      endIndex,
    }
    return delimiter
  }

  /**
   * @override
   * @see IMatchInlineHook
   */
  public processSingleDelimiter(
    delimiter: IDelimiter,
    api: Readonly<IMatchInlinePhaseApi>,
  ): IResultOfProcessSingleDelimiter<T, IToken> {
    if (delimiter.type !== 'full') return []
    const token: IToken = {
      nodeType: InlineWawType,
      startIndex: delimiter.startIndex,
      endIndex: delimiter.endIndex,
    }
    return [token]
  }

  /**
   * @override
   * @see IParseInlineHook
   */
  public processToken(
    token: IToken,
    children: IYastNode[],
    api: Readonly<IParseInlinePhaseApi>,
  ): INode {
    const nodePoints: ReadonlyArray<INodePoint> = api.getNodePoints()
    const { startIndex, endIndex } = token
    let value: string = calcEscapedStringFromNodePoints(
      nodePoints,
      startIndex,
      endIndex
    )

    // Remove the spaces at the end of the line and beginning of the next line.
    value = value.replace(/[^\\\\S\\\\n]*\\\\n[^\\\\S\\\\n]*/g, '\\\\n')
    const node: INode = { type: InlineWawType, value }
    return node
  }
}
"
`;

exports[`new-tokenizer not a monorepo inline: src/types.ts 1`] = `
"import type { IYastLiteral } from '@yozora/ast'
import type {
  IBaseInlineTokenizerProps,
  IPartialYastInlineToken,
  IYastTokenDelimiter,
} from '@yozora/core-tokenizer'

export const InlineWawType = 'inlineWaw'
export type T = typeof InlineWawType

export const uniqueName = '@yozora/tokenizer-inline-waw'

/**
 *
 * @example
 *    \`\`\`\`markdown
 *    \`\`\`\`
 *    ===>
 *    \`\`\`js
 *    \`\`\`
 */
export interface INode extends IYastLiteral<T> {

}

export type IToken = IPartialYastInlineToken<T>

export type IDelimiter = IYastTokenDelimiter

export type ITokenizerProps = Partial<IBaseInlineTokenizerProps>
"
`;

exports[`new-tokenizer not a monorepo inline: tsconfig.json 1`] = `
"{
  \\"extends\\": \\"./tsconfig.settings\\",
  \\"compilerOptions\\": {
    \\"baseUrl\\": \\".\\"
  },
  \\"include\\": [\\"src\\", \\"script\\", \\"__test__\\"]
}
"
`;

exports[`new-tokenizer not a monorepo inline: tsconfig.settings.json 1`] = `
"{
  \\"compilerOptions\\": {
    \\"allowSyntheticDefaultImports\\": true,
    \\"alwaysStrict\\": true,
    \\"declaration\\": true,
    \\"declarationMap\\": false,
    \\"downlevelIteration\\": true,
    \\"esModuleInterop\\": true,
    \\"experimentalDecorators\\": true,
    \\"forceConsistentCasingInFileNames\\": true,
    \\"lib\\": [\\"esnext\\"],
    \\"moduleResolution\\": \\"node\\",
    \\"newLine\\": \\"LF\\",
    \\"noEmit\\": false,
    \\"noEmitOnError\\": true,
    \\"noImplicitAny\\": true,
    \\"noImplicitOverride\\": true,
    \\"noImplicitReturns\\": false,
    \\"noImplicitThis\\": true,
    \\"noImplicitUseStrict\\": false,
    \\"noUnusedLocals\\": false,
    \\"noUnusedParameters\\": false,
    \\"pretty\\": false,
    \\"removeComments\\": false,
    \\"resolveJsonModule\\": true,
    \\"sourceMap\\": false,
    \\"strict\\": true,
    \\"strictFunctionTypes\\": true,
    \\"strictNullChecks\\": true,
    \\"strictPropertyInitialization\\": true,
    \\"suppressImplicitAnyIndexErrors\\": true,
    \\"target\\": \\"es2015\\"
  }
}
"
`;

exports[`new-tokenizer not a monorepo inline: tsconfig.src.json 1`] = `
"{
  \\"extends\\": \\"./tsconfig.settings\\",
  \\"compilerOptions\\": {
    \\"declarationDir\\": \\"lib/types\\",
    \\"rootDir\\": \\"src\\"
  },
  \\"include\\": [\\"src\\"]
}
"
`;
